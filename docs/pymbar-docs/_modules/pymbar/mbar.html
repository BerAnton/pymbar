
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>pymbar.mbar &mdash; pymbar 2.0.0 documentation</title>
    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '2.0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="pymbar 2.0.0 documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../../np-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">pymbar 2.0.0 documentation</a> |</li>
          <li><a href="../index.html" accesskey="U">Module code</a> |</li>
<a href="../../getting_started.html">Getting Started</a> |
<a href="https://github.com/choderalab/pymbar/issues">Bugs</a> |
<a href="../../examples/index.html">Examples</a> |
<a href="../../mdconvert.html"><span class="pre">mdconvert</span></a>
 

      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for pymbar.mbar</h1><div class="highlight"><pre>
<span class="c">#!/usr/bin/env python</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A module implementing the multistate Bennett acceptance ratio (MBAR) method for the analysis</span>
<span class="sd">of equilibrium samples from multiple arbitrary thermodynamic states in computing equilibrium</span>
<span class="sd">expectations, free energy differences, potentials of mean force, and entropy and enthalpy contributions.</span>

<span class="sd">Please reference the following if you use this code in your research:</span>

<span class="sd">[1] Shirts MR and Chodera JD. Statistically optimal analysis of samples from multiple equilibrium states.</span>
<span class="sd">J. Chem. Phys. 129:124105, 2008.  http://dx.doi.org/10.1063/1.2978177</span>

<span class="sd">This module contains implementations of</span>

<span class="sd">* MBAR - multistate Bennett acceptance ratio estimator</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="c">#=========================================================================</span>
<span class="c"># COPYRIGHT NOTICE</span>
<span class="c">#</span>
<span class="c"># Written by John D. Chodera &lt;jchodera@gmail.com&gt; and Michael R. Shirts &lt;mrshirts@gmail.com&gt;.</span>
<span class="c">#</span>
<span class="c"># Copyright (c) 2006-2007 The Regents of the University of California.  All Rights Reserved.</span>
<span class="c"># Portions of this software are Copyright (c) 2007-2008 Stanford University and Columbia University.</span>
<span class="c">#</span>
<span class="c"># This program is free software; you can redistribute it and/or modify it under the terms of</span>
<span class="c"># the GNU General Public License as published by the Free Software Foundation; either version 2</span>
<span class="c"># of the License, or (at your option) any later version.</span>
<span class="c">#</span>
<span class="c"># This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;</span>
<span class="c"># without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</span>
<span class="c"># See the GNU General Public License for more details.</span>
<span class="c">#</span>
<span class="c"># You should have received a copy of the GNU General Public License along with this program;</span>
<span class="c"># if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,</span>
<span class="c"># Boston, MA  02110-1301, USA.</span>
<span class="c">#=========================================================================</span>

<span class="c">#=========================================================================</span>
<span class="c"># TODO</span>
<span class="c"># * Fix computeBAR and computeEXP to be BAR() and EXP() to make them easier to find.</span>
<span class="c"># * Make functions that don&#39;t need to be exported (like logsum) private by prefixing an underscore.</span>
<span class="c"># * Make asymptotic covariance matrix computation more robust to over/underflow.</span>
<span class="c"># * Double-check correspondence of comments to equation numbers once manuscript has been finalized.</span>
<span class="c"># * Change self.nonzero_N_k_indices to self.states_with_samples</span>
<span class="c">#=========================================================================</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">numpy.linalg</span>
<span class="kn">from</span> <span class="nn">pymbar.utils</span> <span class="kn">import</span> <span class="n">_logsum</span><span class="p">,</span> <span class="n">ParameterError</span><span class="p">,</span> <span class="n">ConvergenceError</span><span class="p">,</span> <span class="n">BoundsError</span>

<span class="c">#=========================================================================</span>
<span class="c"># MBAR class definition</span>
<span class="c">#=========================================================================</span>


<div class="viewcode-block" id="MBAR"><a class="viewcode-back" href="../../mbar.html#pymbar.mbar.MBAR">[docs]</a><span class="k">class</span> <span class="nc">MBAR</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Multistate Bennett acceptance ratio method (MBAR) for the analysis of multiple equilibrium samples.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----    </span>
<span class="sd">    Note that this method assumes the data are uncorrelated.</span>
<span class="sd">    Correlated data must be subsampled to extract uncorrelated (effectively independent) samples (see example below).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>

<span class="sd">    [1] Shirts MR and Chodera JD. Statistically optimal analysis of samples from multiple equilibrium states.</span>
<span class="sd">    J. Chem. Phys. 129:124105, 2008</span>
<span class="sd">    http://dx.doi.org/10.1063/1.2978177</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c">#=========================================================================</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u_kln</span><span class="p">,</span> <span class="n">N_k</span><span class="p">,</span> <span class="n">maximum_iterations</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">relative_tolerance</span><span class="o">=</span><span class="mf">1.0e-7</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">initial_f_k</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&#39;adaptive&#39;</span><span class="p">,</span> <span class="n">use_optimized</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">newton_first_gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="n">newton_self_consistent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">maxrange</span><span class="o">=</span><span class="mf">1.0e5</span><span class="p">,</span> <span class="n">initialize</span><span class="o">=</span><span class="s">&#39;zeros&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize multistate Bennett acceptance ratio (MBAR) on a set of simulation data.</span>

<span class="sd">        Upon initialization, the dimensionless free energies for all states are computed.</span>
<span class="sd">        This may take anywhere from seconds to minutes, depending upon the quantity of data.</span>
<span class="sd">        After initialization, the computed free energies may be obtained by a call to &#39;getFreeEnergies()&#39;, or</span>
<span class="sd">        free energies or expectation at any state of interest can be computed by calls to &#39;computeFreeEnergy()&#39; or</span>
<span class="sd">        &#39;computeExpectations()&#39;.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        u_kln : np.ndarray, float, shape=(K, L, N_max)</span>
<span class="sd">            u_kln[k,l,n] is the reduced potential energy of uncorrelated</span>
<span class="sd">            configuration n sampled from state k, evaluated at state l.  K &gt;= L             </span>
<span class="sd">        N_k :  np.ndarray, int, shape=(K)</span>
<span class="sd">            N_k[k] is the number of uncorrelated snapshots sampled from state k</span>
<span class="sd">            This can be zero if the expectation or free energy of this</span>
<span class="sd">            state is desired but no samples were drawn from this state.</span>
<span class="sd">        maximum_iterations : int, optional</span>
<span class="sd">            Set to limit the maximum number of iterations performed (default 1000)</span>
<span class="sd">        relative_tolerance : float, optional</span>
<span class="sd">            Set to determine the relative tolerance convergence criteria (default 1.0e-6)</span>
<span class="sd">        verbosity : bool, optional</span>
<span class="sd">            Set to True if verbose debug output is desired (default False)</span>
<span class="sd">        initial_f_k : np.ndarray, float, shape=(K), optional</span>
<span class="sd">            Set to the initial dimensionless free energies to use as a </span>
<span class="sd">            guess (default None, which sets all f_k = 0)</span>
<span class="sd">        method : string, optional</span>
<span class="sd">            Method for determination of dimensionless free energies: </span>
<span class="sd">            Must be one of &#39;self-consistent-iteration&#39;,&#39;Newton-Raphson&#39;, </span>
<span class="sd">            or &#39;adaptive&#39; (default: &#39;adaptive&#39;).</span>
<span class="sd">            Newton-Raphson is deprecated and defaults to adaptive</span>
<span class="sd">        use_optimized : bool, optional</span>
<span class="sd">            If False, will explicitly disable use of C++ extensions.</span>
<span class="sd">            If None or True, extensions will be autodetected (default: None)</span>
<span class="sd">        initialize : string, optional</span>
<span class="sd">            If equal to &#39;BAR&#39;, use BAR between the pairwise state to </span>
<span class="sd">            initialize the free energies.  Eventually, should specify a path; </span>
<span class="sd">            for now, it just does it zipping up the states. </span>
<span class="sd">            (default: &#39;zeros&#39;, unless specific values are passed in.)            </span>
<span class="sd">        newton_first_gamma : float, optional</span>
<span class="sd">            Initial gamma for newton-raphson (default = 0.1)            </span>
<span class="sd">        newton_self_consistent : int, optional</span>
<span class="sd">            Mininum number of self-consistent iterations before </span>
<span class="sd">            Newton-Raphson iteration (default = 2)</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The reduced potential energy u_kln[k,l,n] = u_l(x_{kn}), where the reduced potential energy u_l(x) is defined (as in the text) by:</span>
<span class="sd">        u_l(x) = beta_l [ U_l(x) + p_l V(x) + mu_l&#39; n(x) ]</span>
<span class="sd">        where</span>
<span class="sd">        beta_l = 1/(kB T_l) is the inverse temperature of condition l, where kB is Boltzmann&#39;s constant</span>
<span class="sd">        U_l(x) is the potential energy function for state l</span>
<span class="sd">        p_l is the pressure at state l (if an isobaric ensemble is specified)</span>
<span class="sd">        V(x) is the volume of configuration x</span>
<span class="sd">        mu_l is the M-vector of chemical potentials for the various species, if a (semi)grand ensemble is specified, and &#39; denotes transpose</span>
<span class="sd">        n(x) is the M-vector of numbers of the various molecular species for configuration x, corresponding to the chemical potential components of mu_m.</span>

<span class="sd">        The configurations x_kn must be uncorrelated.  This can be ensured by subsampling a correlated timeseries with a period larger than the statistical inefficiency,</span>
<span class="sd">        which can be estimated from the potential energy timeseries {u_k(x_kn)}_{n=1}^{N_k} using the provided utility function &#39;statisticalInefficiency()&#39;.</span>
<span class="sd">        See the help for this function for more information.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        &gt;&gt;&gt; import oldtestsystems</span>
<span class="sd">        &gt;&gt;&gt; [x_kn, u_kln, N_k] = oldtestsystems.HarmonicOscillatorsSample()</span>
<span class="sd">        &gt;&gt;&gt; mbar = MBAR(u_kln, N_k)</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;Newton-Raphson&#39;</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;Warning: Newton-Raphson is deprecated.  Switching to method &#39;adaptive&#39; which uses the most quickly converging between Newton-Raphson and self-consistent iteration.&quot;</span>
            <span class="n">method</span> <span class="o">=</span> <span class="s">&#39;adaptive&#39;</span>
        <span class="c"># Determine whether embedded C++ helper code is available</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_embedded_helper_code</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">use_optimized</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">):</span>
            <span class="c"># If user specifies an option, use this.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_embedded_helper_code</span> <span class="o">=</span> <span class="n">use_optimized</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># Test whether we can import the helper code.</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">_pymbar</span>  <span class="c"># import the helper code</span>
                <span class="c"># if we have succeeded, use it</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">use_embedded_helper_code</span> <span class="o">=</span> <span class="bp">True</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="k">print</span> <span class="s">&quot;Using embedded C++ helper code.&quot;</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="c"># import failed</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">use_embedded_helper_code</span> <span class="o">=</span> <span class="bp">False</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="k">print</span> <span class="s">&quot;Could not import working embedded C++ helper code -- using pure Python version instead.&quot;</span>

        <span class="c"># Store local copies of necessary data.</span>
        <span class="c"># N_k[k] is the number of samples from state k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">N_k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="c"># u_kln[k,l,n] is the reduced potential energy of sample n from state k</span>
        <span class="c"># evaluated at state l</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">u_kln</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c"># Get dimensions of reduced potential energy matrix.</span>
        <span class="p">[</span><span class="n">K</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">N_max</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;K = (states with samples) </span><span class="si">%d</span><span class="s">, L (total states) = </span><span class="si">%d</span><span class="s">, N_max = </span><span class="si">%d</span><span class="s">, total samples = </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">N_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">K</span> <span class="o">&gt;</span> <span class="n">L</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span>
                <span class="s">&#39;u_kln[0:K, 0:L, 0:N_max] must have dimensions K &lt;= L.&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">N_k</span> <span class="o">&gt;</span> <span class="n">N_max</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span>
                <span class="s">&#39;All N_k must be &lt;= N_max, the third dimension of u_kln[0:K, 0:L, 0:N_max].&#39;</span><span class="p">)</span>

        <span class="c"># Store local copies of other data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>  <span class="c"># number of thermodynamic states sampled from</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">L</span>  <span class="c"># number of thermodynamic states computed at</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N_max</span> <span class="o">=</span> <span class="n">N_max</span>  <span class="c"># maximum number of configurations per state</span>
        <span class="c"># N = \sum_{k=1}^K N_k is the total number of uncorrelated</span>
        <span class="c"># configurations pooled across all states</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">)</span>
        <span class="c"># verbosity level -- if True, will print extra debug information</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="c"># perform consistency checks on the data.</span>

        <span class="c"># if, for any set of data, all reduced potential energies are the same,</span>
        <span class="c"># they are probably the same state.  We check to within</span>
        <span class="c"># relative_tolerance.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">samestates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">):</span>
            <span class="k">print</span> <span class="s">&#39;Skipping check of whether the states have the same reduced energy,&#39;</span>
            <span class="k">print</span> <span class="s">&#39;as the number of states is greater than 100&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
                    <span class="n">diffsum</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>  <span class="c"># find the nonzero sets of data:</span>
                        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
                            <span class="n">uzero</span> <span class="o">=</span> <span class="n">u_kln</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">u_kln</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">l</span><span class="p">,:]</span>
                            <span class="n">diffsum</span> <span class="o">+=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">uzero</span><span class="p">,</span> <span class="n">uzero</span><span class="p">);</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">diffsum</span> <span class="o">&lt;</span> <span class="n">relative_tolerance</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">samestates</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">])</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">samestates</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">l</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span>
                        <span class="k">print</span> <span class="s">&#39;&#39;</span>
                        <span class="k">print</span> <span class="s">&#39;Warning: states </span><span class="si">%d</span><span class="s"> and </span><span class="si">%d</span><span class="s"> have the same energies on the dataset.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
                        <span class="k">print</span> <span class="s">&#39;They are therefore likely to to be the same thermodynamic state.  This can occasionally cause&#39;</span>
                        <span class="k">print</span> <span class="s">&#39;numerical problems with computing the covariance of their energy difference, which must be&#39;</span>
                        <span class="k">print</span> <span class="s">&#39;identically zero in any case. Consider combining them into a single state.&#39;</span>
                        <span class="k">print</span> <span class="s">&#39;&#39;</span>

        <span class="c"># Create a list of indices of all configurations in kn-indexing.</span>
        <span class="n">mask_kn</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_max</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">):</span>
            <span class="n">mask_kn</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="n">N_k</span><span class="p">[</span><span class="n">k</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="c"># Create a list from this mask.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">indices</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask_kn</span><span class="p">)</span>

        <span class="c"># Determine list of k indices for which N_k != 0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_k</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="c"># Store versions of variables nonzero indices file</span>
        <span class="c"># Number of states with samples.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K_nonzero</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="o">.</span><span class="n">size</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;There are </span><span class="si">%d</span><span class="s"> states with samples.&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">K_nonzero</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">N_nonzero</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c"># Print number of samples from each state.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;N_k = &quot;</span>
            <span class="k">print</span> <span class="n">N_k</span>

        <span class="c"># Initialize estimate of relative dimensionless free energy of each state to zero.</span>
        <span class="c"># Note that f_k[0] will be constrained to be zero throughout.</span>
        <span class="c"># this is default</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c"># If an initial guess of the relative dimensionless free energies is</span>
        <span class="c"># specified, start with that.</span>
        <span class="k">if</span> <span class="n">initial_f_k</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Initializing f_k with provided initial guess.&quot;</span>
            <span class="c"># Cast to numpy array.</span>
            <span class="n">initial_f_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">initial_f_k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="c"># Check shape</span>
            <span class="k">if</span> <span class="n">initial_f_k</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span>
                    <span class="s">&quot;initial_f_k must be a </span><span class="si">%d</span><span class="s">-dimensional numpy array.&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">)</span>
            <span class="c"># Initialize f_k with provided guess.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span> <span class="o">=</span> <span class="n">initial_f_k</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span>
            <span class="c"># Shift all free energies such that f_0 = 0.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[:]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c"># Initialize estimate of relative dimensionless free energies.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initializeFreeEnergies</span><span class="p">(</span><span class="n">verbose</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">initialize</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Initial dimensionless free energies with method </span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">initialize</span><span class="p">)</span>
                <span class="k">print</span> <span class="s">&quot;f_k = &quot;</span>
                <span class="k">print</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span>

        <span class="c"># Solve nonlinear equations for free energies of states with samples.</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">maximum_iterations</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
            <span class="c"># Determine dimensionles free energies.</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;self-consistent-iteration&#39;</span><span class="p">:</span>
                <span class="c"># Use self-consistent iteration of MBAR equations.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_selfConsistentIteration</span><span class="p">(</span>
                    <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">maximum_iterations</span><span class="p">,</span> <span class="n">relative_tolerance</span><span class="o">=</span><span class="n">relative_tolerance</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
            <span class="c"># take both steps at each point, choose &#39;best&#39; by minimum gradient</span>
            <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;adaptive&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_adaptive</span><span class="p">(</span><span class="n">maximum_iterations</span><span class="o">=</span><span class="n">maximum_iterations</span><span class="p">,</span>
                               <span class="n">relative_tolerance</span><span class="o">=</span><span class="n">relative_tolerance</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">print_warning</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span>
                    <span class="s">&quot;Specified method = &#39;</span><span class="si">%s</span><span class="s">&#39; is not a valid method. Specify &#39;self-consistent-iteration&#39; or &#39;adaptive&#39;.&quot;</span><span class="p">)</span>
        <span class="c"># Recompute all free energies because those from states with zero samples are not correctly computed by Newton-Raphson.</span>
        <span class="c"># and store the log weights</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;Recomputing all free energies and log weights for storage&quot;</span>

        <span class="c"># Note: need to recalculate only if max iterations is set to zero.</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeWeights</span><span class="p">(</span>
            <span class="n">recalc_denom</span><span class="o">=</span><span class="p">(</span><span class="n">maximum_iterations</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="n">logform</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">include_nonzero</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_f_k</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="c"># Print final dimensionless free energies.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;Final dimensionless free energies&quot;</span>
            <span class="k">print</span> <span class="s">&quot;f_k = &quot;</span>
            <span class="k">print</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;MBAR initialization complete.&quot;</span>
        <span class="k">return</span>

    <span class="c">#=========================================================================</span>
<div class="viewcode-block" id="MBAR.getWeights"><a class="viewcode-back" href="../../mbar.html#pymbar.mbar.MBAR.getWeights">[docs]</a>    <span class="k">def</span> <span class="nf">getWeights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieve the weight matrix W_nk from the MBAR algorithm.</span>
<span class="sd">        </span>
<span class="sd">        Necessary because they are stored internally as log weights.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        weights : np.ndarray, float, shape=(N, K)</span>
<span class="sd">            NxK matrix of weights in the MBAR covariance and averaging formulas</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span><span class="p">)</span>

    <span class="c">#=========================================================================</span></div>
<div class="viewcode-block" id="MBAR.getFreeEnergyDifferences"><a class="viewcode-back" href="../../mbar.html#pymbar.mbar.MBAR.getFreeEnergyDifferences">[docs]</a>    <span class="k">def</span> <span class="nf">getFreeEnergyDifferences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">compute_uncertainty</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">uncertainty_method</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">warning_cutoff</span><span class="o">=</span><span class="mf">1.0e-10</span><span class="p">,</span> <span class="n">return_theta</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the dimensionless free energy differences and uncertainties among all thermodynamic states.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        compute_uncertainty : bool, optional</span>
<span class="sd">            If False, the uncertainties will not be computed (default: True)</span>
<span class="sd">        uncertainty_method : string, optional</span>
<span class="sd">            Choice of method used to compute asymptotic covariance method,</span>
<span class="sd">            or None to use default.  See help for computeAsymptoticCovarianceMatrix()</span>
<span class="sd">            for more information on various methods. (default: svd)</span>
<span class="sd">        warning_cutoff : float, optional</span>
<span class="sd">            Warn if squared-uncertainty is negative and larger in magnitude</span>
<span class="sd">            than this number (default: 1.0e-10)</span>
<span class="sd">        return_theta : bool, optional </span>
<span class="sd">            Whether or not to return the theta matrix.  Can be useful for complicated differences.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Deltaf_ij :L np.ndarray, float, shape=(K, K)</span>
<span class="sd">            Deltaf_ij[i,j] is the estimated free energy difference</span>
<span class="sd">        dDeltaf_ij :L np.ndarray, float, shape=(K, K)</span>
<span class="sd">            dDeltaf_ij[i,j] is the estimated statistical uncertainty </span>
<span class="sd">            (one standard deviation) in Deltaf_ij[i,j]</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Computation of the covariance matrix may take some time for large K.</span>

<span class="sd">        The reported statistical uncertainty should, in the asymptotic limit, reflect one standard deviation for the normal distribution of the estimate.</span>
<span class="sd">        The true free energy difference should fall within the interval [-df, +df] centered on the estimate 68% of the time, and within</span>
<span class="sd">        the interval [-2 df, +2 df] centered on the estimate 95% of the time.</span>
<span class="sd">        This will break down in cases where the number of samples is not large enough to reach the asymptotic normal limit.</span>

<span class="sd">        See Section III of Reference [1].</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        &gt;&gt;&gt; import oldtestsystems</span>
<span class="sd">        &gt;&gt;&gt; [x_kn, u_kln, N_k] = oldtestsystems.HarmonicOscillatorsSample()</span>
<span class="sd">        &gt;&gt;&gt; mbar = MBAR(u_kln, N_k)</span>
<span class="sd">        &gt;&gt;&gt; [Deltaf_ij, dDeltaf_ij] = mbar.getFreeEnergyDifferences()</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># Compute free energy differences.</span>
        <span class="n">f_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">)</span>
        <span class="n">Deltaf_ij</span> <span class="o">=</span> <span class="n">f_i</span> <span class="o">-</span> <span class="n">f_i</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>

        <span class="c"># zero out numerical error for thermodynamically identical states</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_zerosamestates</span><span class="p">(</span><span class="n">Deltaf_ij</span><span class="p">)</span>

        <span class="n">returns</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Deltaf_ij</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">compute_uncertainty</span> <span class="ow">or</span> <span class="n">return_theta</span><span class="p">:</span>
            <span class="c"># Compute asymptotic covariance matrix.</span>
            <span class="n">Theta_ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeAsymptoticCovarianceMatrix</span><span class="p">(</span>
                <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">uncertainty_method</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">compute_uncertainty</span><span class="p">:</span>
            <span class="c"># compute the covariance component without doing the double loop.</span>
            <span class="c"># d2DeltaF = Theta_ij[i,i] + Theta_ij[j,j] - 2.0 * Theta_ij[i,j]</span>

            <span class="n">diag</span> <span class="o">=</span> <span class="n">Theta_ij</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
            <span class="n">d2DeltaF</span> <span class="o">=</span> <span class="n">diag</span> <span class="o">+</span> <span class="n">diag</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Theta_ij</span>

            <span class="c"># zero out numerical error for thermodynamically identical states</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_zerosamestates</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span>

            <span class="c"># check for any numbers below zero.</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">)):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">warning_cutoff</span><span class="p">):</span>
                    <span class="c"># Hmm.  Will this print correctly?</span>
                    <span class="k">print</span> <span class="s">&quot;A squared uncertainty is negative.  d2DeltaF = </span><span class="si">%e</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">d2DeltaF</span><span class="p">[(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">warning_cutoff</span><span class="p">)]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">d2DeltaF</span><span class="p">[(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">warning_cutoff</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="c"># take the square root of the matrix</span>
            <span class="n">dDeltaf_ij</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span>

            <span class="c"># Return matrix of free energy differences and uncertainties.</span>
            <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dDeltaf_ij</span><span class="p">))</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">return_theta</span><span class="p">):</span>
            <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Theta_ij</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">returns</span>

    <span class="c">#=========================================================================</span>
</div>
<div class="viewcode-block" id="MBAR.computeExpectations"><a class="viewcode-back" href="../../mbar.html#pymbar.mbar.MBAR.computeExpectations">[docs]</a>    <span class="k">def</span> <span class="nf">computeExpectations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A_kn</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="s">&#39;averages&#39;</span><span class="p">,</span> <span class="n">compute_uncertainty</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">uncertainty_method</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">warning_cutoff</span><span class="o">=</span><span class="mf">1.0e-10</span><span class="p">,</span> <span class="n">return_theta</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the expectation of an observable of phase space function.</span>
<span class="sd">         </span>
<span class="sd">        Compute the expectation of an observable of phase space function </span>
<span class="sd">        A(x) at all K states, including states for which no samples </span>
<span class="sd">        were drawn. A may be a function of the state k.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        A : np.ndarray, float          </span>
<span class="sd">            Two possibilities, depending on if the observable is a function of the state or not.</span>
<span class="sd">            either: not dependent on the state</span>
<span class="sd">            A_kn (KxN_max numpy float64 array) - A_kn[k,n] = A(x_kn)</span>
<span class="sd">            or: dependent on state</span>
<span class="sd">            A_kn (KxKxN_max numpy float64 array) - A_kn[k,l,n] = A(x_kn)</span>
<span class="sd">            where the 2nd dimension is the observable as a function of the state</span>

<span class="sd">        output : string, optional</span>
<span class="sd">            Either output averages, and uncertainties, or output a matrix of differences, with uncertainties.</span>
<span class="sd">        compute_uncertainty : bool, optional</span>
<span class="sd">            If False, the uncertainties will not be computed (default: True)</span>
<span class="sd">        uncertainty_method : string, optional</span>
<span class="sd">            Choice of method used to compute asymptotic covariance method, </span>
<span class="sd">            or None to use default See help for computeAsymptoticCovarianceMatrix()</span>
<span class="sd">             for more information on various methods. (default: None)</span>
<span class="sd">        warning_cutoff : float, optional</span>
<span class="sd">            Warn if squared-uncertainty is negative and larger in magnitude than this number (default: 1.0e-10)</span>
<span class="sd">        return_theta : bool, optional</span>
<span class="sd">            Whether or not to return the theta matrix.  Can be useful for complicated differences.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A : np.ndarray, float</span>
<span class="sd">            if output is &#39;averages&#39;</span>
<span class="sd">            A_i  (K numpy float64 array) -  A_i[k] is the estimate for the expectation of A(x) for state k.</span>
<span class="sd">            if output is &#39;differences&#39;</span>
<span class="sd">            A_ij (K numpy float64 array) -  A_ij[i,j] is the difference in the estimates for the expectation of A(x).</span>
<span class="sd">        dA : np.ndarray, float</span>
<span class="sd">            dA_i  (K numpy float64 array) - dA_i[k] is uncertainty estimate (one standard deviation) for A_k[k]</span>
<span class="sd">            or</span>
<span class="sd">            dA_ij (K numpy float64 array) - dA_ij[i,j] is uncertainty estimate (one standard deviation) for the difference in A beteen i and j</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>

<span class="sd">        The reported statistical uncertainty should, in the asymptotic limit, reflect one standard deviation for the normal distribution of the estimate.</span>
<span class="sd">        The true expectation should fall within the interval [-dA, +dA] centered on the estimate 68% of the time, and within</span>
<span class="sd">        the interval [-2 dA, +2 dA] centered on the estimate 95% of the time.</span>
<span class="sd">        This will break down in cases where the number of samples is not large enough to reach the asymptotic normal limit.</span>
<span class="sd">        This &#39;breakdown&#39; can be exacerbated by the computation of observables like indicator functions for histograms that are sparsely populated.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">          </span>
<span class="sd">        See Section IV of [1].</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        &gt;&gt;&gt; import oldtestsystems</span>
<span class="sd">        &gt;&gt;&gt; [x_kn, u_kln, N_k] = oldtestsystems.HarmonicOscillatorsSample()</span>
<span class="sd">        &gt;&gt;&gt; mbar = MBAR(u_kln, N_k)</span>
<span class="sd">        &gt;&gt;&gt; A_kn = x_kn</span>
<span class="sd">        &gt;&gt;&gt; (A_ij, dA_ij) = mbar.computeExpectations(A_kn)</span>
<span class="sd">        &gt;&gt;&gt; A_kn = u_kln</span>
<span class="sd">        &gt;&gt;&gt; (A_ij, dA_ij) = mbar.computeExpectations(A_kn, output=&#39;differences&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># Convert to numpy matrix.</span>
        <span class="n">A_kn</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">A_kn</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c"># Retrieve N and K for convenience.</span>
        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span>

        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A_kn</span><span class="p">))</span>

        <span class="c"># Augment W_nk, N_k, and c_k for q_A(x) for the observable, with one</span>
        <span class="c"># extra row/column for each state (Eq. 13 of [1]).</span>
        <span class="c"># log of weight matrix</span>
        <span class="n">Log_W_nk</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span> <span class="o">*</span> <span class="mi">2</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">N_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span> <span class="o">*</span> <span class="mi">2</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>  <span class="c"># counts</span>
        <span class="c"># &quot;free energies&quot; of the new states</span>
        <span class="n">f_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c"># Fill in first half of matrix with existing q_k(x) from states.</span>
        <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span>
        <span class="n">N_k</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span>

        <span class="c"># Make A_kn all positive so we can operate logarithmically for</span>
        <span class="c"># robustness</span>
        <span class="n">A_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">A_min</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">A_kn</span><span class="p">)</span>
        <span class="n">A_kn</span> <span class="o">=</span> <span class="n">A_kn</span> <span class="o">-</span> <span class="p">(</span><span class="n">A_min</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c"># Compute the remaining rows/columns of W_nk and the rows c_k for the</span>
        <span class="c"># observables.</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">dim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">):</span>
            <span class="c"># Convert A_kn to n = 1..N indexing.</span>
            <span class="n">A_n</span> <span class="o">=</span> <span class="n">A_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">dim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">):</span>
                <span class="n">A_nkstate</span> <span class="o">=</span> <span class="n">A_kn</span><span class="p">[:,</span> <span class="n">l</span><span class="p">,</span> <span class="p">:]</span>
                <span class="n">A_n</span> <span class="o">=</span> <span class="n">A_nkstate</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>

            <span class="c"># this works because all A_n are now positive;</span>
            <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">A_n</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">l</span><span class="p">]</span>
                                                                  <span class="c"># we took the</span>
                                                                  <span class="c"># min at the</span>
                                                                  <span class="c"># beginning.</span>
            <span class="n">f_k</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">_logsum</span><span class="p">(</span><span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">l</span><span class="p">])</span>
            <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">l</span><span class="p">]</span> <span class="o">+=</span> <span class="n">f_k</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>              <span class="c"># normalize the row</span>
            <span class="n">A_i</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">f_k</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">compute_uncertainty</span> <span class="ow">or</span> <span class="n">return_theta</span><span class="p">:</span>
            <span class="c"># Compute augmented asymptotic covariance matrix.</span>
            <span class="n">Theta_ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeAsymptoticCovarianceMatrix</span><span class="p">(</span>
                <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Log_W_nk</span><span class="p">),</span> <span class="n">N_k</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">uncertainty_method</span><span class="p">)</span>

        <span class="n">returns</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">output</span> <span class="o">==</span> <span class="s">&#39;averages&#39;</span><span class="p">:</span>

            <span class="k">if</span> <span class="n">compute_uncertainty</span><span class="p">:</span>
                <span class="c"># Compute uncertainties.</span>
                <span class="n">dA_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
                    <span class="n">dA_i</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">A_i</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                        <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">k</span><span class="p">])</span>  <span class="c"># Eq. 16 of [1]</span>

            <span class="c"># add back minima now now that uncertainties are computed.</span>
            <span class="n">A_i</span> <span class="o">+=</span> <span class="p">(</span><span class="n">A_min</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

            <span class="c"># Return expectations and uncertainties.</span>
            <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">A_i</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">compute_uncertainty</span><span class="p">:</span>
                <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dA_i</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">output</span> <span class="o">==</span> <span class="s">&#39;differences&#39;</span><span class="p">:</span>
            <span class="c"># Return differences of expectations and uncertainties.</span>

            <span class="c"># compute expectation differences</span>
            <span class="n">A_im</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">A_i</span><span class="p">)</span>
            <span class="n">A_ij</span> <span class="o">=</span> <span class="n">A_im</span> <span class="o">-</span> <span class="n">A_im</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>

            <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">A_ij</span><span class="p">))</span>

            <span class="c"># todo - vectorize the differences.</span>

            <span class="k">if</span> <span class="n">compute_uncertainty</span><span class="p">:</span>
                <span class="n">dA_ij</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>

                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">dA_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                              <span class="o">+</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">A_i</span><span class="p">[</span>
                                  <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                                <span class="o">-</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">A_i</span><span class="p">[</span>
                                    <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                                <span class="o">-</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">A_i</span><span class="p">[</span>
                                    <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                                <span class="o">+</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">A_i</span><span class="p">[</span>
                                    <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                                <span class="p">)</span>
                        <span class="k">except</span><span class="p">:</span>
                            <span class="n">dA_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

                <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dA_ij</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">return_theta</span><span class="p">:</span>
                <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Theta_ij</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">returns</span>

    <span class="c">#=========================================================================</span></div>
<div class="viewcode-block" id="MBAR.computeMultipleExpectations"><a class="viewcode-back" href="../../mbar.html#pymbar.mbar.MBAR.computeMultipleExpectations">[docs]</a>    <span class="k">def</span> <span class="nf">computeMultipleExpectations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A_ikn</span><span class="p">,</span> <span class="n">u_kn</span><span class="p">,</span> <span class="n">compute_uncertainty</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">uncertainty_method</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">warning_cutoff</span><span class="o">=</span><span class="mf">1.0e-10</span><span class="p">,</span> <span class="n">return_theta</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the expectations of multiple observables of phase space functions [A_0(x),A_1(x),...,A_n(x)]</span>
<span class="sd">           at single specified state, along with the covariances of their estimates.  The state is specified by</span>
<span class="sd">           the choice of u_kn, which is the energy of the kxn samples evaluated at the chosen state.  Note that</span>
<span class="sd">           these variables A should NOT be functions of the state!</span>

<span class="sd">        REQUIRED ARGUMENTS</span>
<span class="sd">          A_ikn (IxKxN_max numpy float64 array) - A_ikn[i,k,n] = A_i(x_kn), the value of phase observable i for configuration n at state k</span>
<span class="sd">          u_kn (KxN_max numpy float64 array) - u_kn[k,n] is the reduced potential of configuration n gathered from state k, at the state of interest</span>

<span class="sd">        OPTIONAL ARUMENTS</span>
<span class="sd">          uncertainty_method (string) - choice of method used to compute asymptotic covariance method, or None to use default</span>
<span class="sd">                            See help for computeAsymptoticCovarianceMatrix() for more information on various methods. (default: None)</span>
<span class="sd">          uncertainty_method (string) - choice of method used to compute asymptotic covariance method, or None to use default</span>
<span class="sd">                            See help for computeAsymptoticCovarianceMatrix() for more information on various methods. (default: svd)</span>
<span class="sd">          warning_cutoff (float) - warn if squared-uncertainty is negative and larger in magnitude than this number (default: 1.0e-10)</span>
<span class="sd">          return_theta (boolean) - whether or not to return the theta matrix.  Can be useful for complicated differences.</span>

<span class="sd">        RETURN VALUES</span>
<span class="sd">          A_i (I numpy float64 array) - A_i[i] is the estimate for the expectation of A_i(x) at the state specified by u_kn</span>
<span class="sd">          d2A_ij (IxI numpy float64 array) - d2A_ij[i,j] is the COVARIANCE in the estimates of A_i[i] and A_i[j],</span>
<span class="sd">          not the square root of the covariance</span>

<span class="sd">        NOTE: Not fully tested.</span>

<span class="sd">        TESTS</span>

<span class="sd">        &gt;&gt;&gt; import oldtestsystems</span>
<span class="sd">        &gt;&gt;&gt; [x_kn, u_kln, N_k] = oldtestsystems.HarmonicOscillatorsSample()</span>
<span class="sd">        &gt;&gt;&gt; mbar = MBAR(u_kln, N_k)</span>
<span class="sd">        &gt;&gt;&gt; A_ikn = numpy.array([x_kn,x_kn**2,x_kn**3])</span>
<span class="sd">        &gt;&gt;&gt; u_kn = u_kln[:,0,:]</span>
<span class="sd">        &gt;&gt;&gt; [A_i, d2A_ij] = mbar.computeMultipleExpectations(A_ikn, u_kn)</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># Retrieve N and K for convenience.</span>
        <span class="n">I</span> <span class="o">=</span> <span class="n">A_ikn</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c"># number of observables</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span>
        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span>  <span class="c"># N is total number of samples</span>

        <span class="c"># Convert A_kn to n = 1..N indexing.</span>
        <span class="n">A_in</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">I</span><span class="p">,</span> <span class="n">N</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">A_min</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">I</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">I</span><span class="p">):</span>
            <span class="n">A_kn</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">A_ikn</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,:])</span>
            <span class="n">A_in</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">A_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>
            <span class="n">A_min</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">A_in</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span> <span class="c">#find the minimum</span>
            <span class="n">A_in</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-=</span> <span class="p">(</span><span class="n">A_min</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c">#all now values will be positive so that we can work in logarithmic scale</span>

        <span class="c"># Augment W_nk, N_k, and c_k for q_A(x) for the observables, with one</span>
        <span class="c"># row for the specified state and I rows for the observable at that</span>
        <span class="c"># state.</span>
        <span class="c"># log weight matrix</span>
        <span class="n">Log_W_nk</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">I</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">W_nk</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">I</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>  <span class="c"># weight matrix</span>
        <span class="n">N_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">I</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>  <span class="c"># counts</span>
        <span class="n">f_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">I</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>  <span class="c"># free energies</span>

        <span class="c"># Fill in first section of matrix with existing q_k(x) from states.</span>
        <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span>
        <span class="n">W_nk</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span><span class="p">)</span>
        <span class="n">N_k</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span>
        <span class="n">f_k</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span>

        <span class="c"># Compute row of W matrix for the extra state corresponding to u_kn.</span>
        <span class="n">Log_w_kn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeUnnormalizedLogWeights</span><span class="p">(</span><span class="n">u_kn</span><span class="p">)</span>
        <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="n">Log_w_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>
        <span class="n">f_k</span><span class="p">[</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">_logsum</span><span class="p">(</span><span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span><span class="p">])</span>
        <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span><span class="p">]</span> <span class="o">+=</span> <span class="n">f_k</span><span class="p">[</span><span class="n">K</span><span class="p">]</span>

        <span class="c"># Compute the remaining rows/columns of W_nk and c_k for the</span>
        <span class="c"># observables.</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">I</span><span class="p">):</span>
            <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span><span class="o">+</span><span class="mi">1</span><span class="o">+</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">A_in</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span> <span class="o">+</span> <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span><span class="p">]</span>
            <span class="n">f_k</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">_logsum</span><span class="p">(</span><span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">])</span>
            <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">f_k</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span>    <span class="c"># normalize this row</span>

        <span class="c"># Compute estimates.</span>
        <span class="n">A_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">I</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">I</span><span class="p">):</span>
            <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">f_k</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">compute_uncertainty</span> <span class="ow">or</span> <span class="n">return_theta</span><span class="p">:</span>
            <span class="c"># Compute augmented asymptotic covariance matrix.</span>
            <span class="n">W_nk</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Log_W_nk</span><span class="p">)</span>
            <span class="n">Theta_ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeAsymptoticCovarianceMatrix</span><span class="p">(</span>
                <span class="n">W_nk</span><span class="p">,</span> <span class="n">N_k</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">uncertainty_method</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">compute_uncertainty</span><span class="p">:</span>
            <span class="c"># Compute estimates of statistical covariance</span>
            <span class="c"># these variances will be the same whether or not we subtract a different constant from each A_i</span>
            <span class="c"># todo: vectorize</span>
            <span class="c"># compute the covariance component without doing the double loop</span>
            <span class="n">d2A_ij</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">I</span><span class="p">,</span> <span class="n">I</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">I</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">I</span><span class="p">):</span>
                    <span class="n">d2A_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">A_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">Theta_ij</span><span class="p">[</span>
                                                      <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span><span class="p">]</span> <span class="o">-</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">])</span>

        <span class="c"># Now that covariances are computed, add the constants back to A_i that</span>
        <span class="c"># were required to enforce positivity</span>
        <span class="n">A_i</span> <span class="o">+=</span> <span class="p">(</span><span class="n">A_min</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">returns</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">A_i</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">compute_uncertainty</span><span class="p">:</span>
            <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d2A_ij</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_theta</span><span class="p">:</span>
            <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Theta_ij</span><span class="p">)</span>

        <span class="c"># Return expectations and uncertainties.</span>
        <span class="k">return</span> <span class="n">returns</span>

    <span class="c">#=========================================================================</span></div>
<div class="viewcode-block" id="MBAR.computeOverlap"><a class="viewcode-back" href="../../mbar.html#pymbar.mbar.MBAR.computeOverlap">[docs]</a>    <span class="k">def</span> <span class="nf">computeOverlap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="s">&#39;scalar&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute estimate of overlap matrix between the states.</span>

<span class="sd">        RETURNS</span>

<span class="sd">          O (numpy.array of numpy.float64 of dimension [K,K]) - estimated state overlap matrix</span>
<span class="sd">            O[i,j] is an estimate of the probability of observing a sample from state i in state j</span>

<span class="sd">        OPTIONAL ARGUMENTS</span>

<span class="sd">          output (string): One of &#39;scalar&#39;, &#39;matrix&#39;, &#39;eigenvalues&#39;, &#39;all&#39;, specifying what measure</span>
<span class="sd">          of overlap to return</span>

<span class="sd">        NOTES</span>

<span class="sd">        W.T * W \approx \int (p_i p_j /\sum_k N_k p_k)^2 \sum_k N_k p_k dq^N</span>
<span class="sd">                      = \int (p_i p_j /\sum_k N_k p_k) dq^N</span>

<span class="sd">        Multiplying elementwise by N_i, the elements of row i give the probability</span>
<span class="sd">        for a sample from state i being observed in state j.</span>

<span class="sd">        TEST</span>

<span class="sd">        &gt;&gt;&gt; import oldtestsystems</span>
<span class="sd">        &gt;&gt;&gt; [x_kn, u_kln, N_k] = oldtestsystems.HarmonicOscillatorsSample()</span>
<span class="sd">        &gt;&gt;&gt; mbar = MBAR(u_kln, N_k)</span>
<span class="sd">        &gt;&gt;&gt; O_ij = mbar.computeOverlap()</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">W</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">getWeights</span><span class="p">(),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">O</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">W</span><span class="p">)</span>
        <span class="p">(</span><span class="n">eigenval</span><span class="p">,</span> <span class="n">eigevec</span><span class="p">)</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">O</span><span class="p">)</span>
        <span class="c"># sort in descending order</span>
        <span class="n">eigenval</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">eigenval</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">overlap_scalar</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">eigenval</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">output</span> <span class="o">==</span> <span class="s">&#39;scalar&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">overlap_scalar</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">output</span> <span class="o">==</span> <span class="s">&#39;eigenvalues&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">eigenval</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">output</span> <span class="o">==</span> <span class="s">&#39;matrix&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">O</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">output</span> <span class="o">==</span> <span class="s">&#39;all&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">overlap_scalar</span><span class="p">,</span> <span class="n">eigenval</span><span class="p">,</span> <span class="n">O</span>

    <span class="c">#=========================================================================</span></div>
<div class="viewcode-block" id="MBAR.computePerturbedExpectation"><a class="viewcode-back" href="../../mbar.html#pymbar.mbar.MBAR.computePerturbedExpectation">[docs]</a>    <span class="k">def</span> <span class="nf">computePerturbedExpectation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u_kn</span><span class="p">,</span> <span class="n">A_kn</span><span class="p">,</span> <span class="n">compute_uncertainty</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">uncertainty_method</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">warning_cutoff</span><span class="o">=</span><span class="mf">1.0e-10</span><span class="p">,</span> <span class="n">return_theta</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the expectation of an observable of phase space function A(x) for a single new state.</span>

<span class="sd">        REQUIRED ARGUMENTS</span>
<span class="sd">          u_kn (KxN_max numpy float64 array) - u_kn[k,n] = u(x_kn) - the energy of the new state at all N samples previously sampled.</span>
<span class="sd">          A_kn (KxN_max numpy float64 array) - A_kn[k,n] = A(x_kn) - the phase space function of the new state at all N samples previously sampled.  If this does NOT depend on state (e.g. position), it&#39;s simply the value of the observation.  If it DOES depend on the current state, then the observables from the previous states need to be reevaluated at THIS state.</span>

<span class="sd">        OPTIONAL ARUMENTS</span>
<span class="sd">          compute_uncertainty (boolean) - if set to False, the uncertainties will not be computed (default: True)</span>
<span class="sd">          uncertainty_method (string) - choice of method used to compute asymptotic covariance method, or None to use default</span>
<span class="sd">                            See help for computeAsymptoticCovarianceMatrix() for more information on various methods. (default: None)</span>
<span class="sd">          warning_cutoff (float) - warn if squared-uncertainty is negative and larger in magnitude than this number (default: 1.0e-10)</span>
<span class="sd">          return_theta (boolean) - whether or not to return the theta matrix.  Can be useful for complicated differences.</span>

<span class="sd">        RETURN VALUES</span>
<span class="sd">          A (double) - A is the estimate for the expectation of A(x) for the specified state</span>
<span class="sd">          dA (double) - dA is uncertainty estimate for A</span>

<span class="sd">        REFERENCE</span>
<span class="sd">          See Section IV of [1].</span>
<span class="sd">        # Compute estimators and uncertainty.</span>
<span class="sd">        #A = sum(W_nk[:,K] * A_n[:]) # Eq. 15 of [1]</span>
<span class="sd">        #dA = abs(A) * numpy.sqrt(Theta_ij[K,K] + Theta_ij[K+1,K+1] - 2.0 * Theta_ij[K,K+1]) # Eq. 16 of [1]</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># Convert to numpy matrix.</span>
        <span class="n">A_kn</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">A_kn</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c"># Retrieve N and K for convenience.</span>
        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span>

        <span class="c"># Make A_kn all positive so we can operate logarithmically for</span>
        <span class="c"># robustness</span>
        <span class="n">A_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">A_min</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">A_kn</span><span class="p">)</span>
        <span class="n">A_kn</span> <span class="o">=</span> <span class="n">A_kn</span> <span class="o">-</span> <span class="p">(</span><span class="n">A_min</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c"># Convert A_kn to n = 1..N indexing.</span>
        <span class="n">A_n</span> <span class="o">=</span> <span class="n">A_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>

        <span class="c"># Augment W_nk, N_k, and c_k for q_A(x) for the observable, with one</span>
        <span class="c"># extra row/column for the specified state (Eq. 13 of [1]).</span>
        <span class="c"># weight matrix</span>
        <span class="n">Log_W_nk</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">N_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span> <span class="o">+</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>  <span class="c"># counts</span>
        <span class="n">f_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span> <span class="o">+</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>  <span class="c"># free energies</span>

        <span class="c"># Fill in first K states with existing q_k(x) from states.</span>
        <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span>
        <span class="n">N_k</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span>

        <span class="c"># compute the free energy of the additional state</span>
        <span class="n">log_w_kn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeUnnormalizedLogWeights</span><span class="p">(</span><span class="n">u_kn</span><span class="p">)</span>
        <span class="c"># Compute free energies</span>
        <span class="n">f_k</span><span class="p">[</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">_logsum</span><span class="p">(</span><span class="n">log_w_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">])</span>
        <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="n">log_w_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span> <span class="o">+</span> <span class="n">f_k</span><span class="p">[</span><span class="n">K</span><span class="p">]</span>

        <span class="c"># compute the observable at this state</span>
        <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">A_n</span><span class="p">)</span> <span class="o">+</span> <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span><span class="p">]</span>
        <span class="n">f_k</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">_logsum</span><span class="p">(</span><span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">f_k</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>              <span class="c"># normalize the row</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">f_k</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">compute_uncertainty</span> <span class="ow">or</span> <span class="n">return_theta</span><span class="p">):</span>
            <span class="c"># Compute augmented asymptotic covariance matrix.</span>
            <span class="n">Theta_ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeAsymptoticCovarianceMatrix</span><span class="p">(</span>
                <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Log_W_nk</span><span class="p">),</span> <span class="n">N_k</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">uncertainty_method</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">compute_uncertainty</span><span class="p">):</span>
            <span class="n">dA</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>  <span class="c"># Eq. 16 of [1]</span>

        <span class="c"># shift answers back with the offset now that variances are computed</span>
        <span class="n">A</span> <span class="o">+=</span> <span class="p">(</span><span class="n">A_min</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">returns</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">compute_uncertainty</span><span class="p">):</span>
            <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dA</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">return_theta</span><span class="p">):</span>
            <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

        <span class="c"># Return expectations and uncertainties.</span>
        <span class="k">return</span> <span class="n">returns</span>

    <span class="c">#=========================================================================</span></div>
<div class="viewcode-block" id="MBAR.computePerturbedFreeEnergies"><a class="viewcode-back" href="../../mbar.html#pymbar.mbar.MBAR.computePerturbedFreeEnergies">[docs]</a>    <span class="k">def</span> <span class="nf">computePerturbedFreeEnergies</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u_kln</span><span class="p">,</span> <span class="n">compute_uncertainty</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">uncertainty_method</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">warning_cutoff</span><span class="o">=</span><span class="mf">1.0e-10</span><span class="p">,</span> <span class="n">return_theta</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the free energies for a new set of states.</span>
<span class="sd">        Here, we desire the free energy differences among a set of new states, as well as the uncertainty estimates in these differences.</span>

<span class="sd">        REQUIRED ARGUMENTS</span>
<span class="sd">          u_kln (KxLxNmax float array) - u_kln[k,l,n] is the reduced potential energy of uncorrelated configuration n sampled from state k, evaluated at new state l.</span>
<span class="sd">            L need not be the same as K.</span>

<span class="sd">        OPTINAL ARUMENTS</span>
<span class="sd">          compute_uncertainty (boolean) - if set to False, the uncertainties will not be computed (default: True)</span>
<span class="sd">          uncertainty_method (string) - choice of method used to compute asymptotic covariance method, or None to use default</span>
<span class="sd">                            See help for computeAsymptoticCovarianceMatrix() for more information on various methods. (default: None)</span>
<span class="sd">          warning_cutoff (float) - warn if squared-uncertainty is negative and larger in magnitude than this number (default: 1.0e-10)</span>

<span class="sd">        RETURN VALUES</span>
<span class="sd">          Deltaf_ij (LxL numpy float64 array) - Deltaf_ij[i,j] = f_j - f_i, the dimensionless free energy difference between new states i and j</span>
<span class="sd">          dDeltaf_ij (LxL numpy float64 array) - dDeltaf_ij[i,j] is the estimated statistical uncertainty in Deltaf_ij[i,j]</span>

<span class="sd">        TEST</span>

<span class="sd">        &gt;&gt;&gt; import oldtestsystems</span>
<span class="sd">        &gt;&gt;&gt; [x_kn, u_kln, N_k] = oldtestsystems.HarmonicOscillatorsSample()</span>
<span class="sd">        &gt;&gt;&gt; mbar = MBAR(u_kln, N_k)</span>
<span class="sd">        &gt;&gt;&gt; [Deltaf_ij, dDeltaf_ij] = mbar.computePerturbedFreeEnergies(u_kln)</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># Convert to numpy matrix.</span>
        <span class="n">u_kln</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">u_kln</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c"># Get the dimensions of the matrix of reduced potential energies.</span>
        <span class="p">[</span><span class="n">K</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">N_max</span><span class="p">]</span> <span class="o">=</span> <span class="n">u_kln</span><span class="o">.</span><span class="n">shape</span>

        <span class="c"># Check dimensions.</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">K</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">):</span>
            <span class="k">raise</span> <span class="s">&quot;K-dimension of u_kln must be the same as K-dimension of original states.&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">N_max</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="o">.</span><span class="n">max</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="s">&quot;There seems to be too few samples in u_kln.&quot;</span>

        <span class="c"># Retrieve N and K for convenience.</span>
        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span>

        <span class="c"># Augment W_nk, N_k, and c_k for the new states.</span>
        <span class="n">W_nk</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">L</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>  <span class="c"># weight matrix</span>
        <span class="n">N_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span> <span class="o">+</span> <span class="n">L</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>  <span class="c"># counts</span>
        <span class="n">f_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span> <span class="o">+</span> <span class="n">L</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>  <span class="c"># free energies</span>

        <span class="c"># Fill in first half of matrix with existing q_k(x) from states.</span>
        <span class="n">W_nk</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span><span class="p">)</span>
        <span class="n">N_k</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span>
        <span class="n">f_k</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span>

        <span class="c"># Compute normalized weights.</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">L</span><span class="p">):</span>
            <span class="c"># Compute unnormalized log weights.</span>
            <span class="n">log_w_kn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeUnnormalizedLogWeights</span><span class="p">(</span><span class="n">u_kln</span><span class="p">[:,</span> <span class="n">l</span><span class="p">,</span> <span class="p">:])</span>
            <span class="c"># Compute free energies</span>
            <span class="n">f_k</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="n">_logsum</span><span class="p">(</span><span class="n">log_w_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">])</span>
            <span class="c"># Store normalized weights.  Keep in exponential not log form</span>
            <span class="c"># because we will not store W_nk</span>
            <span class="n">W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_w_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span> <span class="o">+</span> <span class="n">f_k</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">l</span><span class="p">])</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">compute_uncertainty</span> <span class="ow">or</span> <span class="n">return_theta</span><span class="p">):</span>
            <span class="c"># Compute augmented asymptotic covariance matrix.</span>
            <span class="n">Theta_ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeAsymptoticCovarianceMatrix</span><span class="p">(</span>
                <span class="n">W_nk</span><span class="p">,</span> <span class="n">N_k</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">uncertainty_method</span><span class="p">)</span>

        <span class="c"># Compute matrix of free energy differences between states and</span>
        <span class="c"># associated uncertainties.</span>
        <span class="c"># makes matrix operations easier to recast</span>
        <span class="n">f_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">f_k</span><span class="p">[</span><span class="n">K</span><span class="p">:</span><span class="n">K</span> <span class="o">+</span> <span class="n">L</span><span class="p">])</span>

        <span class="n">Deltaf_ij</span> <span class="o">=</span> <span class="n">f_k</span> <span class="o">-</span> <span class="n">f_k</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>

        <span class="n">returns</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Deltaf_ij</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">compute_uncertainty</span><span class="p">):</span>
            <span class="n">diag</span> <span class="o">=</span> <span class="n">Theta_ij</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
            <span class="n">dii</span> <span class="o">=</span> <span class="n">diag</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">K</span><span class="p">:</span><span class="n">K</span> <span class="o">+</span> <span class="n">L</span><span class="p">]</span>
            <span class="n">d2DeltaF</span> <span class="o">=</span> <span class="n">dii</span> <span class="o">+</span> <span class="n">dii</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span><span class="p">:</span><span class="n">K</span> <span class="o">+</span> <span class="n">L</span><span class="p">,</span> <span class="n">K</span><span class="p">:</span><span class="n">K</span> <span class="o">+</span> <span class="n">L</span><span class="p">]</span>

            <span class="c"># check for any numbers below zero.</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">)):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">warning_cutoff</span><span class="p">):</span>
                    <span class="k">print</span> <span class="s">&quot;A squared uncertainty is negative.  d2DeltaF = </span><span class="si">%e</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">d2DeltaF</span><span class="p">[(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">warning_cutoff</span><span class="p">)]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">d2DeltaF</span><span class="p">[(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">warning_cutoff</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="c"># take the square root of the matrix</span>
            <span class="n">dDeltaf_ij</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span>

            <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dDeltaf_ij</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">return_theta</span><span class="p">):</span>
            <span class="n">returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Theta_ij</span><span class="p">)</span>

        <span class="c"># Return matrix of free energy differences and uncertainties.</span>
        <span class="k">return</span> <span class="n">returns</span>
</div>
<div class="viewcode-block" id="MBAR.computeEntropyAndEnthalpy"><a class="viewcode-back" href="../../mbar.html#pymbar.mbar.MBAR.computeEntropyAndEnthalpy">[docs]</a>    <span class="k">def</span> <span class="nf">computeEntropyAndEnthalpy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">uncertainty_method</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">warning_cutoff</span><span class="o">=</span><span class="mf">1.0e-10</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the decomposition of the free energy difference between states 1 and N into reduced free energy differences, reduced potential (enthalpy) differences, and reduced entropy (S/k) differences.</span>

<span class="sd">        OPTINAL ARUMENTS</span>
<span class="sd">          uncertainty_method (string) - choice of method used to compute asymptotic covariance method, or None to use default</span>
<span class="sd">                            See help for computeAsymptoticCovarianceMatrix() for more information on various methods. (default: None)</span>
<span class="sd">          warning_cutoff (float) - warn if squared-uncertainty is negative and larger in magnitude than this number (default: 1.0e-10)</span>
<span class="sd">        RETURN VALUES</span>
<span class="sd">          Delta_f_ij (KxK numpy float matrix) - Delta_f_ij[i,j] is the dimensionless free energy difference f_j - f_i</span>
<span class="sd">          dDelta_f_ij (KxK numpy float matrix) - uncertainty in Delta_f_ij</span>
<span class="sd">          Delta_u_ij (KxK numpy float matrix) - Delta_u_ij[i,j] is the reduced potential energy difference u_j - u_i</span>
<span class="sd">          dDelta_u_ij (KxK numpy float matrix) - uncertainty in Delta_f_ij</span>
<span class="sd">          Delta_s_ij (KxK numpy float matrix) - Delta_s_ij[i,j] is the reduced entropy difference S/k between states i and j (s_j - s_i)</span>
<span class="sd">          dDelta_s_ij (KxK numpy float matrix) - uncertainty in Delta_s_ij</span>

<span class="sd">        WARNING</span>
<span class="sd">          This method is EXPERIMENTAL and should be used at your own risk.</span>

<span class="sd">        TEST</span>

<span class="sd">        &gt;&gt;&gt; import oldtestsystems</span>
<span class="sd">        &gt;&gt;&gt; [x_kn, u_kln, N_k] = oldtestsystems.HarmonicOscillatorsSample()</span>
<span class="sd">        &gt;&gt;&gt; mbar = MBAR(u_kln, N_k)</span>
<span class="sd">        &gt;&gt;&gt; [Delta_f_ij, dDelta_f_ij, Delta_u_ij, dDelta_u_ij, Delta_s_ij, dDelta_s_ij] = mbar.computeEntropyAndEnthalpy()</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;Computing average energy and entropy by MBAR.&quot;</span>

        <span class="c"># Retrieve N and K for convenience.</span>
        <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span>

        <span class="c"># Augment W_nk, N_k, and c_k for q_A(x) for the potential energies,</span>
        <span class="c"># with one extra row/column for each state.</span>
        <span class="c"># weight matrix</span>
        <span class="n">Log_W_nk</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span> <span class="o">*</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">N_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span> <span class="o">*</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>  <span class="c"># counts</span>
        <span class="c"># &quot;free energies&quot; of average states</span>
        <span class="n">f_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c"># Fill in first half of matrix with existing q_k(x) from states.</span>
        <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span>
        <span class="n">N_k</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span>

        <span class="c"># Compute the remaining rows/columns of W_nk and c_k for the potential</span>
        <span class="c"># energy observable.</span>

        <span class="n">u_min</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="n">u_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
            <span class="c"># Convert potential energies to n = 1..N indexing.</span>
            <span class="n">u_kn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span><span class="p">[:,</span> <span class="n">l</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="p">(</span><span class="n">u_min</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c"># all positive now!  Subtracting off arbitrary constants doesn&#39;t affect results.</span>
                                                  <span class="c"># since they are all differences.</span>
            <span class="c"># Compute unnormalized weights.</span>
            <span class="c"># A(x_n) exp[f_{k} - q_{k}(x_n)] / \sum_{k&#39;=1}^K N_{k&#39;} exp[f_{k&#39;} - q_{k&#39;}(x_n)]</span>
            <span class="c"># harden for over/underflow with logarithms</span>

            <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="n">u_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">l</span><span class="p">]</span>

            <span class="n">f_k</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">_logsum</span><span class="p">(</span><span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">l</span><span class="p">])</span>
            <span class="n">Log_W_nk</span><span class="p">[:,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">l</span><span class="p">]</span> <span class="o">+=</span> <span class="n">f_k</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>              <span class="c"># normalize the row</span>
            <span class="n">u_i</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">f_k</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>

            <span class="c"># print &quot;MBAR u_i[%d]: %10.5f,%10.5f&quot; % (l,u_i[l]+u_min, u_i[l])</span>

        <span class="c"># Compute augmented asymptotic covariance matrix.</span>
        <span class="n">W_nk</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Log_W_nk</span><span class="p">)</span>
        <span class="n">Theta_ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeAsymptoticCovarianceMatrix</span><span class="p">(</span>
            <span class="n">W_nk</span><span class="p">,</span> <span class="n">N_k</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">uncertainty_method</span><span class="p">)</span>

        <span class="c"># Compute estimators and uncertainties.</span>
        <span class="n">dDelta_f_ij</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">dDelta_u_ij</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">dDelta_s_ij</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c"># Compute reduced free energy difference.</span>
        <span class="n">f_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">)</span>
        <span class="n">Delta_f_ij</span> <span class="o">=</span> <span class="n">f_k</span> <span class="o">-</span> <span class="n">f_k</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>

        <span class="c"># Compute reduced enthalpy difference.</span>
        <span class="n">u_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">u_i</span><span class="p">)</span>
        <span class="n">Delta_u_ij</span> <span class="o">=</span> <span class="n">u_k</span> <span class="o">-</span> <span class="n">u_k</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>

        <span class="c"># Compute reduced entropy difference</span>
        <span class="n">s_k</span> <span class="o">=</span> <span class="n">u_k</span> <span class="o">-</span> <span class="n">f_k</span>
        <span class="n">Delta_s_ij</span> <span class="o">=</span> <span class="n">s_k</span> <span class="o">-</span> <span class="n">s_k</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>

        <span class="c"># compute uncertainty matrix in free energies:</span>
        <span class="c"># d2DeltaF = Theta_ij[i,i] + Theta_ij[j,j] - 2.0 * Theta_ij[i,j]</span>

        <span class="n">diag</span> <span class="o">=</span> <span class="n">Theta_ij</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
        <span class="n">dii</span> <span class="o">=</span> <span class="n">diag</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span>
        <span class="n">d2DeltaF</span> <span class="o">=</span> <span class="n">dii</span> <span class="o">+</span> <span class="n">dii</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span>

        <span class="c"># check for any numbers below zero.</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">)):</span>
            <span class="k">if</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">warning_cutoff</span><span class="p">):</span>
                <span class="c"># Hmm.  Will this print correctly?</span>
                <span class="k">print</span> <span class="s">&quot;A squared uncertainty is negative.  d2DeltaF = </span><span class="si">%e</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">d2DeltaF</span><span class="p">[(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">warning_cutoff</span><span class="p">)]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">d2DeltaF</span><span class="p">[(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">warning_cutoff</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="c"># take the square root of the matrix</span>
        <span class="n">dDelta_f_ij</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d2DeltaF</span><span class="p">)</span>

        <span class="c"># TODO -- vectorize this calculation for entropy and enthalpy!</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">dDelta_u_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                      <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">u_i</span><span class="p">[</span>
                          <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                      <span class="o">-</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span>
                          <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                      <span class="o">-</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span>
                          <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                      <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span>
                          <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                      <span class="p">)</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="n">dDelta_u_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

                <span class="c"># Compute reduced entropy difference.</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">dDelta_s_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                      <span class="o">+</span> <span class="p">(</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span>
                          <span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                      <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span>
                         <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span>
                          <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                      <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span>
                         <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span>
                          <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                      <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span>
                                                          <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">u_i</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">u_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                      <span class="p">)</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="n">dDelta_s_ij</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="c"># Return expectations and uncertainties.</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">Delta_f_ij</span><span class="p">,</span> <span class="n">dDelta_f_ij</span><span class="p">,</span> <span class="n">Delta_u_ij</span><span class="p">,</span> <span class="n">dDelta_u_ij</span><span class="p">,</span> <span class="n">Delta_s_ij</span><span class="p">,</span> <span class="n">dDelta_s_ij</span><span class="p">)</span>
    <span class="c">#=========================================================================</span>
</div>
<div class="viewcode-block" id="MBAR.computePMF"><a class="viewcode-back" href="../../mbar.html#pymbar.mbar.MBAR.computePMF">[docs]</a>    <span class="k">def</span> <span class="nf">computePMF</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u_kn</span><span class="p">,</span> <span class="n">bin_kn</span><span class="p">,</span> <span class="n">nbins</span><span class="p">,</span> <span class="n">uncertainties</span><span class="o">=</span><span class="s">&#39;from-lowest&#39;</span><span class="p">,</span> <span class="n">pmf_reference</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the free energy of occupying a number of bins.</span>
<span class="sd">        This implementation computes the expectation of an indicator-function observable for each bin.</span>

<span class="sd">        REQUIRED ARGUMENTS</span>
<span class="sd">          u_kn[k,n] is the reduced potential energy of snapshot n of state k for which the PMF is to be computed.</span>
<span class="sd">          bin_kn[k,n] is the bin index of snapshot n of state k.  bin_kn can assume a value in range(0,nbins)</span>
<span class="sd">          nbins is the number of bins</span>

<span class="sd">        OPTIONAL ARGUMENTS</span>
<span class="sd">          uncertainties (string) - choose method for reporting uncertainties (default: &#39;from-lowest&#39;)</span>
<span class="sd">            &#39;from-lowest&#39; - the uncertainties in the free energy difference with lowest point on PMF are reported</span>
<span class="sd">            &#39;from-reference&#39; - same as from lowest, but from a user specified point</span>
<span class="sd">            &#39;from-normalization&#39; - the normalization \sum_i p_i = 1 is used to determine uncertainties spread out through the PMF</span>
<span class="sd">            &#39;all-differences&#39; - the nbins x nbins matrix df_ij of uncertainties in free energy differences is returned instead of df_i</span>

<span class="sd">        RETURN VALUES</span>
<span class="sd">          f_i[i], i = 0..nbins - the dimensionless free energy of state i, relative to the state of lowest free energy</span>
<span class="sd">          df_i[i] is the uncertainty in the difference of f_i with respect to the state of lowest free energy</span>

<span class="sd">        NOTES</span>
<span class="sd">          All bins must have some samples in them from at least one of the states -- this will not work if bin_kn.sum(0) == 0. Empty bins should be removed before calling computePMF().</span>
<span class="sd">          This method works by computing the free energy of localizing the system to each bin for the given potential by aggregating the log weights for the given potential.</span>
<span class="sd">          To estimate uncertainties, the NxK weight matrix W_nk is augmented to be Nx(K+nbins) in order to accomodate the normalized weights of states where</span>
<span class="sd">          the potential is given by u_kn within each bin and infinite potential outside the bin.  The uncertainties with respect to the bin of lowest free energy</span>
<span class="sd">          are then computed in the standard way.</span>

<span class="sd">        WARNING</span>
<span class="sd">          This method is EXPERIMENTAL and should be used at your own risk.</span>

<span class="sd">        TEST</span>

<span class="sd">        &gt;&gt;&gt; import oldtestsystems</span>
<span class="sd">        &gt;&gt;&gt; [x_kn, u_kln, N_k] = oldtestsystems.HarmonicOscillatorsSample(N_k=[100,100,100])</span>
<span class="sd">        &gt;&gt;&gt; mbar = MBAR(u_kln, N_k)</span>
<span class="sd">        &gt;&gt;&gt; u_kn = u_kln[0,:,:]</span>
<span class="sd">        &gt;&gt;&gt; xmin = x_kn.min()</span>
<span class="sd">        &gt;&gt;&gt; xmax = x_kn.max()</span>
<span class="sd">        &gt;&gt;&gt; nbins = 10</span>
<span class="sd">        &gt;&gt;&gt; dx = (xmax - xmin) * 1.00001 / float(nbins)</span>
<span class="sd">        &gt;&gt;&gt; bin_kn = numpy.array((x_kn - xmin) / dx, numpy.int32)</span>
<span class="sd">        &gt;&gt;&gt; [f_i, df_i] = mbar.computePMF(u_kn, bin_kn, nbins)</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># Verify that no PMF bins are empty -- we can&#39;t deal with empty bins,</span>
        <span class="c"># because the free energy is infinite.</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbins</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">bin_kn</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span>
                    <span class="s">&quot;At least one bin in provided bin_kn argument has no samples.  All bins must have samples for free energies to be finite.  Adjust bin sizes or eliminate empty bins to ensure at least one sample per bin.&quot;</span><span class="p">)</span>

        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span>

        <span class="c"># Compute unnormalized log weights for the given reduced potential</span>
        <span class="c"># u_kn.</span>
        <span class="n">log_w_kn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeUnnormalizedLogWeights</span><span class="p">(</span><span class="n">u_kn</span><span class="p">)</span>

        <span class="c"># Unroll to n-indices</span>
        <span class="n">log_w_n</span> <span class="o">=</span> <span class="n">log_w_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>

        <span class="c"># Compute the free energies for these states.</span>
        <span class="n">f_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">nbins</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">df_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">nbins</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbins</span><span class="p">):</span>
            <span class="c"># Get linear n-indices of samples that fall in this bin.</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">bin_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c"># Compute dimensionless free energy of occupying state i.</span>
            <span class="n">f_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="n">_logsum</span><span class="p">(</span><span class="n">log_w_n</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span>

        <span class="c"># Compute uncertainties by forming matrix of W_nk.</span>
        <span class="n">N_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">+</span> <span class="n">nbins</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">N_k</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span>
        <span class="n">W_nk</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">+</span> <span class="n">nbins</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">W_nk</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbins</span><span class="p">):</span>
            <span class="c"># Get indices of samples that fall in this bin.</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">bin_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c"># Compute normalized weights for this state.</span>
            <span class="n">W_nk</span><span class="p">[</span><span class="n">indices</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_w_n</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">+</span> <span class="n">f_i</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="c"># Compute asymptotic covariance matrix using specified method.</span>
        <span class="n">Theta_ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeAsymptoticCovarianceMatrix</span><span class="p">(</span><span class="n">W_nk</span><span class="p">,</span> <span class="n">N_k</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">uncertainties</span> <span class="o">==</span> <span class="s">&#39;from-lowest&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">uncertainties</span> <span class="o">==</span> <span class="s">&#39;from-specified&#39;</span><span class="p">):</span>
            <span class="c"># Report uncertainties in free energy difference from lowest point</span>
            <span class="c"># on PMF.</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">uncertainties</span> <span class="o">==</span> <span class="s">&#39;from-lowest&#39;</span><span class="p">):</span>
                <span class="c"># Determine bin index with lowest free energy.</span>
                <span class="n">j</span> <span class="o">=</span> <span class="n">f_i</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
            <span class="k">elif</span> <span class="p">(</span><span class="n">uncertainties</span> <span class="o">==</span> <span class="s">&#39;from-specified&#39;</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">pmf_reference</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span>
                        <span class="s">&quot;no reference state specified for PMF using uncertainties = from-reference&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">j</span> <span class="o">=</span> <span class="n">pmf_reference</span>
            <span class="c"># Compute uncertainties with respect to difference in free energy</span>
            <span class="c"># from this state j.</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbins</span><span class="p">):</span>
                <span class="n">df_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                    <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">])</span>

            <span class="c"># Shift free energies so that state j has zero free energy.</span>
            <span class="n">f_i</span> <span class="o">-=</span> <span class="n">f_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

            <span class="c"># Return dimensionless free energy and uncertainty.</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">f_i</span><span class="p">,</span> <span class="n">df_i</span><span class="p">)</span>

        <span class="k">elif</span> <span class="p">(</span><span class="n">uncertainties</span> <span class="o">==</span> <span class="s">&#39;all-differences&#39;</span><span class="p">):</span>
            <span class="c"># Report uncertainties in all free energy differences.</span>

            <span class="n">diag</span> <span class="o">=</span> <span class="n">Theta_ij</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
            <span class="n">dii</span> <span class="o">=</span> <span class="n">diag</span><span class="p">[</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">nbins</span><span class="p">]</span>
            <span class="n">d2f_ij</span> <span class="o">=</span> <span class="n">dii</span> <span class="o">+</span> \
                <span class="n">dii</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span><span class="p">:</span><span class="n">K</span> <span class="o">+</span> <span class="n">nbins</span><span class="p">,</span> <span class="n">K</span><span class="p">:</span><span class="n">K</span> <span class="o">+</span> <span class="n">nbins</span><span class="p">]</span>

            <span class="c"># unsquare uncertainties</span>
            <span class="n">df_ij</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d2f_ij</span><span class="p">)</span>

            <span class="c"># Return dimensionless free energy and uncertainty.</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">f_i</span><span class="p">,</span> <span class="n">df_ij</span><span class="p">)</span>

        <span class="k">elif</span> <span class="p">(</span><span class="n">uncertainties</span> <span class="o">==</span> <span class="s">&#39;from-normalization&#39;</span><span class="p">):</span>
            <span class="c"># Determine uncertainties from normalization that \sum_i p_i = 1.</span>

            <span class="c"># Compute bin probabilities p_i</span>
            <span class="n">p_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">f_i</span> <span class="o">-</span> <span class="n">_logsum</span><span class="p">(</span><span class="o">-</span><span class="n">f_i</span><span class="p">))</span>

            <span class="c"># todo -- eliminate triple loop over nbins!</span>
            <span class="c"># Compute uncertainties in bin probabilities.</span>
            <span class="n">d2p_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">nbins</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbins</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbins</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbins</span><span class="p">):</span>
                        <span class="n">delta_ik</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="n">k</span><span class="p">)</span>
                        <span class="n">delta_jk</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">j</span> <span class="o">==</span> <span class="n">k</span><span class="p">)</span>
                        <span class="n">d2p_i</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">p_i</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">p_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">delta_ik</span><span class="p">)</span> <span class="o">*</span> <span class="n">p_i</span><span class="p">[</span>
                                              <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">p_i</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">delta_jk</span><span class="p">)</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span>

            <span class="c"># Transform from d2p_i to df_i</span>
            <span class="n">d2f_i</span> <span class="o">=</span> <span class="n">d2p_i</span> <span class="o">/</span> <span class="n">p_i</span> <span class="o">**</span> <span class="mi">2</span>
            <span class="n">df_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d2f_i</span><span class="p">)</span>

            <span class="c"># return free energy and uncertainty</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">f_i</span><span class="p">,</span> <span class="n">df_i</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="s">&quot;Uncertainty method &#39;</span><span class="si">%s</span><span class="s">&#39; not recognized.&quot;</span> <span class="o">%</span> <span class="n">uncertainties</span>

        <span class="k">return</span>

    <span class="c">#=========================================================================</span></div>
<div class="viewcode-block" id="MBAR.computePMF_states"><a class="viewcode-back" href="../../mbar.html#pymbar.mbar.MBAR.computePMF_states">[docs]</a>    <span class="k">def</span> <span class="nf">computePMF_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u_kn</span><span class="p">,</span> <span class="n">bin_kn</span><span class="p">,</span> <span class="n">nbins</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the free energy of occupying a number of bins.</span>
<span class="sd">        This implementation defines each bin as a separate thermodynamic state.</span>

<span class="sd">        REQUIRED ARGUMENTS</span>
<span class="sd">          u_kn[k,n] is the reduced potential energy of snapshot n of state k for which the PMF is to be computed.</span>
<span class="sd">          bin_kn[k,n] is the bin index of snapshot n of state k.  bin_kn can assume a value in range(0,nbins)</span>
<span class="sd">          nbins is the number of bins</span>

<span class="sd">        OPTIONAL ARGUMENTS</span>
<span class="sd">          fmax is the maximum value of the free energy, used for an empty bin (default: 1000)</span>

<span class="sd">        RETURN VALUES</span>
<span class="sd">          f_i[i], i = 0..nbins - the dimensionless free energy of state i, relative to the state of lowest free energy</span>
<span class="sd">          d2f_ij[i,j] is the uncertainty in the difference of (f_i - f_j)</span>

<span class="sd">        NOTES</span>
<span class="sd">          All bins must have some samples in them from at least one of the states -- this will not work if bin_kn.sum(0) == 0. Empty bins should be removed before calling computePMF().</span>
<span class="sd">          This method works by computing the free energy of localizing the system to each bin for the given potential by aggregating the log weights for the given potential.</span>
<span class="sd">          To estimate uncertainties, the NxK weight matrix W_nk is augmented to be Nx(K+nbins) in order to accomodate the normalized weights of states where</span>
<span class="sd">          the potential is given by u_kn within each bin and infinite potential outside the bin.  The uncertainties with respect to the bin of lowest free energy</span>
<span class="sd">          are then computed in the standard way.</span>

<span class="sd">        WARNING</span>
<span class="sd">          This method is EXPERIMENTAL and should be used at your own risk.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># Verify that no PMF bins are empty -- we can&#39;t deal with empty bins,</span>
        <span class="c"># because the free energy is infinite.</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbins</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">bin_kn</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span>
                    <span class="s">&quot;At least one bin in provided bin_kn argument has no samples.  All bins must have samples for free energies to be finite.  Adjust bin sizes or eliminate empty bins to ensure at least one sample per bin.&quot;</span><span class="p">)</span>

        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span>

        <span class="c"># Compute unnormalized log weights for the given reduced potential</span>
        <span class="c"># u_kn.</span>
        <span class="n">log_w_kn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeUnnormalizedLogWeights</span><span class="p">(</span><span class="n">u_kn</span><span class="p">)</span>
        <span class="c"># Unroll to n-indices</span>
        <span class="n">log_w_n</span> <span class="o">=</span> <span class="n">log_w_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>

        <span class="c"># Compute the free energies for these states.</span>
        <span class="n">f_i</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">nbins</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbins</span><span class="p">):</span>
            <span class="c"># Get linear n-indices of samples that fall in this bin.</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">bin_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c"># Sanity check.</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="k">raise</span> <span class="s">&quot;WARNING: bin </span><span class="si">%d</span><span class="s"> has no samples -- all bins must have at least one sample.&quot;</span> <span class="o">%</span> <span class="n">i</span>

            <span class="c"># Compute dimensionless free energy of occupying state i.</span>
            <span class="n">f_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="n">_logsum</span><span class="p">(</span><span class="n">log_w_n</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span>

        <span class="c"># Shift so that f_i.min() = 0</span>
        <span class="n">f_i_min</span> <span class="o">=</span> <span class="n">f_i</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="n">f_i</span> <span class="o">-=</span> <span class="n">f_i</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;bins f_i = &quot;</span>
            <span class="k">print</span> <span class="n">f_i</span>

        <span class="c"># Compute uncertainties by forming matrix of W_nk.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;Forming W_nk matrix...&quot;</span>
        <span class="n">N_k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">+</span> <span class="n">nbins</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">N_k</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span>
        <span class="n">W_nk</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">+</span> <span class="n">nbins</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">W_nk</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Log_W_nk</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbins</span><span class="p">):</span>
            <span class="c"># Get indices of samples that fall in this bin.</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">bin_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;bin </span><span class="si">%5d</span><span class="s"> count = </span><span class="si">%10d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>

            <span class="c"># Compute normalized weights for this state.</span>
            <span class="n">W_nk</span><span class="p">[</span><span class="n">indices</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
                <span class="n">log_w_n</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">+</span> <span class="n">f_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">f_i_min</span><span class="p">)</span>

        <span class="c"># Compute asymptotic covariance matrix using specified method.</span>
        <span class="n">Theta_ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeAsymptoticCovarianceMatrix</span><span class="p">(</span><span class="n">W_nk</span><span class="p">,</span> <span class="n">N_k</span><span class="p">)</span>

        <span class="c"># Compute uncertainties with respect to difference in free energy from</span>
        <span class="c"># this state j.</span>
        <span class="n">diag</span> <span class="o">=</span> <span class="n">Theta_ij</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
        <span class="n">dii</span> <span class="o">=</span> <span class="n">diag</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">K</span><span class="p">:</span><span class="n">K</span> <span class="o">+</span> <span class="n">nbins</span><span class="p">]</span>
        <span class="n">d2f_ij</span> <span class="o">=</span> <span class="n">dii</span> <span class="o">+</span> <span class="n">dii</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Theta_ij</span><span class="p">[</span><span class="n">K</span><span class="p">:</span><span class="n">K</span> <span class="o">+</span> <span class="n">nbins</span><span class="p">,</span> <span class="n">K</span><span class="p">:</span><span class="n">K</span> <span class="o">+</span> <span class="n">nbins</span><span class="p">]</span>

        <span class="c"># Return dimensionless free energy and uncertainty.</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">f_i</span><span class="p">,</span> <span class="n">d2f_ij</span><span class="p">)</span>

    <span class="c">#=========================================================================</span>
    <span class="c"># PRIVATE METHODS - INTERFACES ARE NOT EXPORTED</span>
    <span class="c">#=========================================================================</span>
</div>
    <span class="k">def</span> <span class="nf">_computeWeights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logform</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">include_nonzero</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">recalc_denom</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_f_k</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the normalized weights corresponding to samples for the given reduced potential.</span>
<span class="sd">        Also stores the all_log_denom array for reuse.</span>

<span class="sd">        INPUT VALUES</span>

<span class="sd">        logform (bool): whether the output is in logarithmic form, which is better for stability, though sometimes</span>
<span class="sd">                        the exponential form is requires.</span>
<span class="sd">        include_nonzero (bool): whether to compute weights for states with nonzero states.  Not necessary</span>
<span class="sd">                                 when performing self-consistent iteration.</span>
<span class="sd">        recalc_denom (bool): recalculate the denominator, must be done if the free energies change.</span>
<span class="sd">                             default is to do it, so that errors are not made.  But can be turned</span>
<span class="sd">                             off if it is known the free energies have not changed.</span>
<span class="sd">        return_f_k (bool): return the self-consistent f_k values</span>

<span class="sd">        RETURN VALUES</span>

<span class="sd">        if logform==True:</span>
<span class="sd">          Log_W_nk (double) - Log_W_nk[n,k] is the normalized log weight of sample n from state k.</span>
<span class="sd">        else:</span>
<span class="sd">          W_nk (double) - W_nk[n,k] is the log weight of sample n from state k.</span>
<span class="sd">        if return_f_k==True:</span>
<span class="sd">          optionally return the self-consistent free energy from these weights.</span>

<span class="sd">       &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">include_nonzero</span><span class="p">):</span>
            <span class="n">f_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span>
            <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span>
            <span class="n">N_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">f_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">]</span>
            <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K_nonzero</span>
            <span class="n">N_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_nonzero</span>

        <span class="c"># array of either weights or normalized log weights</span>
        <span class="n">Warray_nk</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">return_f_k</span><span class="p">):</span>
            <span class="n">f_k_out</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">recalc_denom</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_weight_denom</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeUnnormalizedLogWeights</span><span class="p">(</span>
                <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_max</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
            <span class="c"># Compute log weights.</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">include_nonzero</span><span class="p">):</span>
                <span class="n">index</span> <span class="o">=</span> <span class="n">l</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
            <span class="n">log_w_kn</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span><span class="p">[:,</span> <span class="n">index</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_weight_denom</span> <span class="o">+</span> <span class="n">f_k</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">return_f_k</span><span class="p">):</span>
                <span class="n">f_k_out</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">f_k</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">-</span> <span class="n">_logsum</span><span class="p">(</span><span class="n">log_w_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">])</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">include_nonzero</span><span class="p">):</span>
                    <span class="c"># renormalize the weights, needed for nonzero states.</span>
                    <span class="n">log_w_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">f_k_out</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">-</span> <span class="n">f_k</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">logform</span><span class="p">):</span>
                <span class="n">Warray_nk</span><span class="p">[:,</span> <span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">log_w_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">Warray_nk</span><span class="p">[:,</span> <span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_w_kn</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">])</span>

        <span class="c"># Return weights (or log weights)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">return_f_k</span><span class="p">):</span>
            <span class="n">f_k_out</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">f_k_out</span><span class="p">[:]</span> <span class="o">-</span> <span class="n">f_k_out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">Warray_nk</span><span class="p">,</span> <span class="n">f_k_out</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Warray_nk</span>

    <span class="c">#=========================================================================</span>

    <span class="k">def</span> <span class="nf">_pseudoinverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1.0e-10</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the Moore-Penrose pseudoinverse.</span>

<span class="sd">        REQUIRED ARGUMENTS</span>
<span class="sd">          A (numpy KxK matrix) - the square matrix whose pseudoinverse is to be computed</span>

<span class="sd">        RETURN VALUES</span>
<span class="sd">          Ainv (numpy KxK matrix) - the pseudoinverse</span>

<span class="sd">        OPTIONAL VALUES</span>
<span class="sd">          tol - the tolerance (relative to largest magnitude singlular value) below which singular values are to not be include in forming pseudoinverse (default: 1.0e-10)</span>

<span class="sd">        NOTES</span>
<span class="sd">          This implementation is provided because the &#39;pinv&#39; function of numpy is broken in the version we were using.</span>

<span class="sd">        TODO</span>
<span class="sd">          Can we get rid of this and use numpy.linalg.pinv instead?</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># DEBUG</span>
        <span class="c"># TODO: Should we use pinv, or _pseudoinverse?</span>
        <span class="c"># return numpy.linalg.pinv(A)</span>

        <span class="c"># Get size</span>
        <span class="p">[</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">N</span> <span class="o">!=</span> <span class="n">M</span><span class="p">:</span>
            <span class="k">raise</span> <span class="s">&quot;pseudoinverse can only be computed for square matrices: dimensions were </span><span class="si">%d</span><span class="s"> x </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

        <span class="c"># Make sure A contains no nan.</span>
        <span class="k">if</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">A</span><span class="p">))):</span>
            <span class="k">print</span> <span class="s">&quot;attempted to compute pseudoinverse of A =&quot;</span>
            <span class="k">print</span> <span class="n">A</span>
            <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span><span class="s">&quot;A contains nan.&quot;</span><span class="p">)</span>

        <span class="c"># DEBUG</span>
        <span class="n">diagonal_loading</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">if</span> <span class="n">diagonal_loading</span><span class="p">:</span>
            <span class="c"># Modify matrix by diagonal loading.</span>
            <span class="n">eigs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
            <span class="n">most_negative_eigenvalue</span> <span class="o">=</span> <span class="n">eigs</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">most_negative_eigenvalue</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">):</span>
                <span class="k">print</span> <span class="s">&quot;most negative eigenvalue = </span><span class="si">%e</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">most_negative_eigenvalue</span>
                <span class="c"># Choose loading value.</span>
                <span class="n">gamma</span> <span class="o">=</span> <span class="o">-</span><span class="n">most_negative_eigenvalue</span> <span class="o">*</span> <span class="mf">1.05</span>
                <span class="c"># Modify Theta by diagonal loading</span>
                <span class="n">A</span> <span class="o">+=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c"># Compute SVD of A.</span>
        <span class="p">[</span><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vt</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

        <span class="c"># Compute pseudoinverse by taking square root of nonzero singular</span>
        <span class="c"># values.</span>
        <span class="n">Ainv</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">M</span><span class="p">,</span> <span class="n">M</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">S</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">tol</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">S</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
                <span class="n">Ainv</span> <span class="o">+=</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">S</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">U</span><span class="p">[:,</span> <span class="n">k</span><span class="p">],</span> <span class="n">Vt</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">T</span>

        <span class="k">return</span> <span class="n">Ainv</span>
    <span class="c">#=========================================================================</span>

    <span class="k">def</span> <span class="nf">_zerosamestates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        zeros out states that should be identical</span>

<span class="sd">        REQUIRED ARGUMENTS</span>

<span class="sd">        A: the matrix whose entries are to be zeroed.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">samestates</span><span class="p">:</span>
            <span class="n">A</span><span class="p">[</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">A</span><span class="p">[</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c">#=========================================================================</span>
    <span class="k">def</span> <span class="nf">_computeAsymptoticCovarianceMatrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">N_k</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute estimate of the asymptotic covariance matrix.</span>

<span class="sd">        REQUIRED ARGUMENTS</span>
<span class="sd">          W (numpy.array of numpy.float of dimension [N,K]) - matrix of normalized weights (see Eq. 9 of [1]) - W[n,k] is the weight of snapshot n (n = 1..N) in state k</span>
<span class="sd">                                          Note that sum(W(:,k)) = 1 for any k = 1..K, and sum(N_k(:) .* W(n,:)) = 1 for any n.</span>
<span class="sd">          N_k (numpy.array of numpy.int32 of dimension [K]) - N_k[k] is the number of samples from state K</span>

<span class="sd">        RETURN VALUES</span>
<span class="sd">          Theta (KxK numpy float64 array) - asymptotic covariance matrix (see Eq. 8 of [1])</span>

<span class="sd">        OPTIONAL ARGUMENTS</span>
<span class="sd">          method (string) - if not None, specified method is used to compute asymptotic covariance method:</span>
<span class="sd">                            method must be one of [&#39;generalized-inverse&#39;, &#39;svd&#39;, &#39;svd-ew&#39;, &#39;inverse&#39;, &#39;tan-HGH&#39;, &#39;tan&#39;, &#39;approximate&#39;]</span>
<span class="sd">                            If None is specified, &#39;svd-ew&#39; is used.</span>

<span class="sd">        NOTES</span>

<span class="sd">        The computational costs of the various &#39;method&#39; arguments varies:</span>

<span class="sd">          &#39;generalized-inverse&#39; currently requires computation of the pseudoinverse of an NxN matrix (where N is the total number of samples)</span>
<span class="sd">          &#39;svd&#39; computes the generalized inverse using the singular value decomposition -- this should be efficient yet accurate (faster)</span>
<span class="sd">          &#39;svd-ev&#39; is the same as &#39;svd&#39;, but uses the eigenvalue decomposition of W&#39;W to bypass the need to perform an SVD (fastest)</span>
<span class="sd">          &#39;inverse&#39; only requires standard inversion of a KxK matrix (where K is the number of states), but requires all K states to be different</span>
<span class="sd">          &#39;approximate&#39; only requires multiplication of KxN and NxK matrices, but is an approximate underestimate of the uncertainty</span>
<span class="sd">          &#39;tan&#39; uses a simplified form that requires two pseudoinversions, but can be unstable</span>
<span class="sd">          &#39;tan-HGH&#39; makes weaker assumptions on &#39;tan&#39; but can occasionally be unstable</span>

<span class="sd">        REFERENCE</span>
<span class="sd">          See Section II and Appendix D of [1].</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># Set &#39;svd-ew&#39; as default if uncertainty method specified as None.</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">method</span> <span class="o">=</span> <span class="s">&#39;svd-ew&#39;</span>

        <span class="c"># Get dimensions of weight matrix.</span>
        <span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span>

        <span class="c"># Check dimensions</span>
        <span class="k">if</span><span class="p">(</span><span class="n">K</span> <span class="o">!=</span> <span class="n">N_k</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span>
                <span class="s">&#39;W must be NxK, where N_k is a K-dimensional array.&#39;</span><span class="p">)</span>
        <span class="k">if</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">N_k</span><span class="p">)</span> <span class="o">!=</span> <span class="n">N</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span><span class="s">&#39;W must be NxK, where N = sum_k N_k.&#39;</span><span class="p">)</span>

        <span class="c"># Check to make sure the weight matrix W is properly normalized.</span>
        <span class="n">tolerance</span> <span class="o">=</span> <span class="mf">1.0e-4</span>  <span class="c"># tolerance for checking equality of sums</span>

        <span class="n">column_sums</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">badcolumns</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">column_sums</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">tolerance</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">badcolumns</span><span class="p">):</span>
            <span class="n">which_badcolumns</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">K</span><span class="p">)[</span><span class="n">badcolumns</span><span class="p">]</span>
            <span class="n">firstbad</span> <span class="o">=</span> <span class="n">which_badcolumns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span>
                <span class="s">&#39;Warning: Should have \sum_n W_nk = 1.  Actual column sum for state </span><span class="si">%d</span><span class="s"> was </span><span class="si">%f</span><span class="s">. </span><span class="si">%d</span><span class="s"> other columns have similar problems&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">firstbad</span><span class="p">,</span> <span class="n">column_sums</span><span class="p">[</span><span class="n">firstbad</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">badcolumns</span><span class="p">)))</span>

        <span class="n">row_sums</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W</span> <span class="o">*</span> <span class="n">N_k</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">badrows</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">row_sums</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">tolerance</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">badrows</span><span class="p">):</span>
            <span class="n">which_badrows</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)[</span><span class="n">badrows</span><span class="p">]</span>
            <span class="n">firstbad</span> <span class="o">=</span> <span class="n">which_badrows</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span>
                <span class="s">&#39;Warning: Should have \sum_k N_k W_nk = 1.  Actual row sum for sample </span><span class="si">%d</span><span class="s"> was </span><span class="si">%f</span><span class="s">. </span><span class="si">%d</span><span class="s"> other rows have similar problems&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">firstbad</span><span class="p">,</span> <span class="n">row_sums</span><span class="p">[</span><span class="n">firstbad</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">badrows</span><span class="p">)))</span>

        <span class="c"># Compute estimate of asymptotic covariance matrix using specified</span>
        <span class="c"># method.</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;generalized-inverse&#39;</span><span class="p">:</span>
            <span class="c"># Use generalized inverse (Eq. 8 of [1]) -- most general</span>
            <span class="c"># Theta = W&#39; (I - W N W&#39;)^+ W</span>

            <span class="c"># Construct matrices</span>
            <span class="c"># Diagonal N_k matrix.</span>
            <span class="n">Ndiag</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">N_k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

            <span class="c"># Compute covariance</span>
            <span class="n">Theta</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pseudoinverse</span><span class="p">(</span><span class="n">I</span> <span class="o">-</span> <span class="n">W</span> <span class="o">*</span> <span class="n">Ndiag</span> <span class="o">*</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="n">W</span>

        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;inverse&#39;</span><span class="p">:</span>
            <span class="c"># Use standard inverse method (Eq. D8 of [1]) -- only applicable if all K states are different</span>
            <span class="c"># Theta = [(W&#39;W)^-1 - N + 1 1&#39;/N]^-1</span>

            <span class="c"># Construct matrices</span>
            <span class="c"># Diagonal N_k matrix.</span>
            <span class="n">Ndiag</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">N_k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="c"># matrix of ones, times 1/N</span>
            <span class="n">O</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>

            <span class="c"># Make sure W is nonsingular.</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">W</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">tolerance</span><span class="p">):</span>
                <span class="k">print</span> <span class="s">&quot;Warning: W&#39;W appears to be singular, yet &#39;inverse&#39; method of uncertainty estimation requires W contain no duplicate states.&quot;</span>

            <span class="c"># Compute covariance</span>
            <span class="n">Theta</span> <span class="o">=</span> <span class="p">((</span><span class="n">W</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">W</span><span class="p">)</span><span class="o">.</span><span class="n">I</span> <span class="o">-</span> <span class="n">Ndiag</span> <span class="o">+</span> <span class="n">O</span><span class="p">)</span><span class="o">.</span><span class="n">I</span>

        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;approximate&#39;</span><span class="p">:</span>
            <span class="c"># Use fast approximate expression from Kong et al. -- this underestimates the true covariance, but may be a good approximation in some cases and requires no matrix inversions</span>
            <span class="c"># Theta = P&#39;P</span>

            <span class="c"># Construct matrices</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

            <span class="c"># Compute covariance</span>
            <span class="n">Theta</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">W</span>

        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;svd&#39;</span><span class="p">:</span>
            <span class="c"># Use singular value decomposition based approach given in supplementary material to efficiently compute uncertainty</span>
            <span class="c"># See Appendix D.1, Eq. D4 in [1].</span>

            <span class="c"># Construct matrices</span>
            <span class="n">Ndiag</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">N_k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

            <span class="c"># Compute SVD of W</span>
            <span class="p">[</span><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vt</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
            <span class="n">Sigma</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>
            <span class="n">V</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">Vt</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

            <span class="c"># Compute covariance</span>
            <span class="n">Theta</span> <span class="o">=</span> <span class="n">V</span> <span class="o">*</span> <span class="n">Sigma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pseudoinverse</span><span class="p">(</span>
                <span class="n">I</span> <span class="o">-</span> <span class="n">Sigma</span> <span class="o">*</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">Ndiag</span> <span class="o">*</span> <span class="n">V</span> <span class="o">*</span> <span class="n">Sigma</span><span class="p">)</span> <span class="o">*</span> <span class="n">Sigma</span> <span class="o">*</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span>

        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;svd-ew&#39;</span><span class="p">:</span>
            <span class="c"># Use singular value decomposition based approach given in supplementary material to efficiently compute uncertainty</span>
            <span class="c"># The eigenvalue decomposition of W&#39;W is used to forego computing the SVD.</span>
            <span class="c"># See Appendix D.1, Eqs. D4 and D5 of [1].</span>

            <span class="c"># Construct matrices</span>
            <span class="n">Ndiag</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">N_k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

            <span class="c"># Compute singular values and right singular vectors of W without using SVD</span>
            <span class="c"># Instead, we compute eigenvalues and eigenvectors of W&#39;W.</span>
            <span class="c"># Note W&#39;W = (U S V&#39;)&#39;(U S V&#39;) = V S&#39; U&#39; U S V&#39; = V (S&#39;S) V&#39;</span>
            <span class="p">[</span><span class="n">S2</span><span class="p">,</span> <span class="n">V</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">W</span><span class="p">)</span>
            <span class="c"># Set any slightly negative eigenvalues to zero.</span>
            <span class="n">S2</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">S2</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="c"># Form matrix of singular values Sigma, and V.</span>
            <span class="n">Sigma</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S2</span><span class="p">)))</span>
            <span class="n">V</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>

            <span class="c"># Compute covariance</span>
            <span class="n">Theta</span> <span class="o">=</span> <span class="n">V</span> <span class="o">*</span> <span class="n">Sigma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pseudoinverse</span><span class="p">(</span>
                <span class="n">I</span> <span class="o">-</span> <span class="n">Sigma</span> <span class="o">*</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">Ndiag</span> <span class="o">*</span> <span class="n">V</span> <span class="o">*</span> <span class="n">Sigma</span><span class="p">)</span> <span class="o">*</span> <span class="n">Sigma</span> <span class="o">*</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span>

        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;tan-HGH&#39;</span><span class="p">:</span>
            <span class="c"># Use method suggested by Zhiqiang Tan without further simplification.</span>
            <span class="c"># TODO: There may be a problem here -- double-check this.</span>

            <span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">]</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span>

            <span class="c"># Estimate O matrix from W&#39;W.</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">O</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">W</span>

            <span class="c"># Assemble the Lambda matrix.</span>
            <span class="n">Lambda</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">N_k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

            <span class="c"># Identity matrix.</span>
            <span class="n">I</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">K</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

            <span class="c"># Compute H and G matrices.</span>
            <span class="n">H</span> <span class="o">=</span> <span class="n">O</span> <span class="o">*</span> <span class="n">Lambda</span> <span class="o">-</span> <span class="n">I</span>
            <span class="n">G</span> <span class="o">=</span> <span class="n">O</span> <span class="o">-</span> <span class="n">O</span> <span class="o">*</span> <span class="n">Lambda</span> <span class="o">*</span> <span class="n">O</span>

            <span class="c"># Compute pseudoinverse of H</span>
            <span class="n">Hinv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pseudoinverse</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>

            <span class="c"># Compute estimate of asymptotic covariance.</span>
            <span class="n">Theta</span> <span class="o">=</span> <span class="n">Hinv</span> <span class="o">*</span> <span class="n">G</span> <span class="o">*</span> <span class="n">Hinv</span><span class="o">.</span><span class="n">T</span>

        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;tan&#39;</span><span class="p">:</span>
            <span class="c"># Use method suggested by Zhiqiang Tan.</span>

            <span class="c"># Estimate O matrix from W&#39;W.</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">O</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">W</span>

            <span class="c"># Assemble the Lambda matrix.</span>
            <span class="n">Lambda</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">N_k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

            <span class="c"># Compute covariance.</span>
            <span class="n">Oinv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pseudoinverse</span><span class="p">(</span><span class="n">O</span><span class="p">)</span>
            <span class="n">Theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pseudoinverse</span><span class="p">(</span><span class="n">Oinv</span> <span class="o">-</span> <span class="n">Lambda</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c"># Raise an exception.</span>
            <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span><span class="s">&#39;Method &#39;</span> <span class="o">+</span> <span class="n">method</span> <span class="o">+</span> <span class="s">&#39; unrecognized.&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">Theta</span>
    <span class="c">#=========================================================================</span>

    <span class="k">def</span> <span class="nf">_initializeFreeEnergies</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&#39;zeros&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute an initial guess at the relative free energies.</span>

<span class="sd">        OPTIONAL ARGUMENTS</span>
<span class="sd">          verbose (boolean) - If True, will print debug information (default: False)</span>
<span class="sd">          method (string) - Method for initializing guess at free energies.</span>
<span class="sd">            &#39;zeros&#39; - all free energies are initially set to zero</span>
<span class="sd">            &#39;mean-reduced-potential&#39; - the mean reduced potential is used</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">method</span> <span class="o">==</span> <span class="s">&#39;zeros&#39;</span><span class="p">):</span>
            <span class="c"># Use zeros for initial free energies.</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Initializing free energies to zero.&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[:]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">method</span> <span class="o">==</span> <span class="s">&#39;mean-reduced-potential&#39;</span><span class="p">):</span>
            <span class="c"># Compute initial guess at free energies from the mean reduced</span>
            <span class="c"># potential from each state</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;Initializing free energies with mean reduced potential for each state.&quot;</span>
            <span class="n">means</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">],</span> <span class="nb">float</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">:</span>
                <span class="n">means</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">[</span><span class="n">k</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">means</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">0.000001</span><span class="p">):</span>
                <span class="k">print</span> <span class="s">&quot;Warning: All mean reduced potentials are close to zero. If you are using energy differences in the u_kln matrix, then the mean reduced potentials will be zero, and this is expected behavoir.&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span> <span class="o">=</span> <span class="n">means</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">method</span> <span class="o">==</span> <span class="s">&#39;BAR&#39;</span><span class="p">):</span>
            <span class="c"># TODO: Can we guess a good path for this initial guess for arbitrary &quot;topologies&quot;?</span>
            <span class="c"># For now, make a simple list of those states with samples.</span>
            <span class="n">initialization_order</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c"># Initialize all f_k to zero.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[:]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="c"># Initialize the rest</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">initialization_order</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">initialization_order</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
                <span class="n">l</span> <span class="o">=</span> <span class="n">initialization_order</span><span class="p">[</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                <span class="c"># forward work</span>
                <span class="n">w_F</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">[</span><span class="n">k</span><span class="p">]]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">[</span><span class="n">k</span><span class="p">]])</span>
                <span class="c"># reverse work</span>
                <span class="n">w_R</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span><span class="p">[</span><span class="n">l</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">[</span><span class="n">l</span><span class="p">]]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span><span class="p">[</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">[</span><span class="n">l</span><span class="p">]])</span>

                <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">w_F</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">w_R</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="c"># BAR solution doesn&#39;t need to be incredibly accurate to</span>
                    <span class="c"># kickstart NR.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">BAR</span><span class="p">(</span>
                        <span class="n">w_F</span><span class="p">,</span> <span class="n">w_R</span><span class="p">,</span> <span class="n">relative_tolerance</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">compute_uncertainty</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c"># no states observed, so we don&#39;t need to initialize this free energy anyway, as</span>
                    <span class="c"># the solution is noniterative.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c"># The specified method is not implemented.</span>
            <span class="k">raise</span> <span class="n">ParameterError</span><span class="p">(</span><span class="s">&#39;Method &#39;</span> <span class="o">+</span> <span class="n">method</span> <span class="o">+</span> <span class="s">&#39; unrecognized.&#39;</span><span class="p">)</span>

        <span class="c"># Shift all free energies such that f_0 = 0.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[:]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span>
    <span class="c">#=========================================================================</span>

    <span class="k">def</span> <span class="nf">_computeUnnormalizedLogWeights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u_kn</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return unnormalized log weights.</span>

<span class="sd">        REQUIRED ARGUMENTS</span>
<span class="sd">          u_kn (K x N_max numpy float64 array) - reduced potential energies</span>

<span class="sd">        OPTIONAL ARGUMENTS</span>

<span class="sd">        RETURN VALUES</span>
<span class="sd">          log_w_kn (K x N_max numpy float64 array) - unnormalized log weights</span>

<span class="sd">        REFERENCE</span>
<span class="sd">          &#39;log weights&#39; here refers to \log [ \sum_{k=1}^K N_k exp[f_k - (u_k(x_n) - u(x_n)] ]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">use_embedded_helper_code</span><span class="p">):</span>
            <span class="c"># Use embedded C++ optimizations.</span>
            <span class="kn">import</span> <span class="nn">_pymbar</span>
            <span class="c"># necessary for helper code to interpret type of u_kn</span>
            <span class="n">u_kn</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">u_kn</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">log_w_kn</span> <span class="o">=</span> <span class="n">_pymbar</span><span class="o">.</span><span class="n">computeUnnormalizedLogWeightsCpp</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">K_nonzero</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span><span class="p">,</span> <span class="n">u_kn</span><span class="p">);</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c">#z= 1/0</span>
                <span class="c"># pass</span>
                <span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">weave</span>
                <span class="c"># Allocate storage for return values.</span>
                <span class="n">log_w_kn</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_max</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
                <span class="c"># Copy useful class members to local variables.</span>
                <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span>
                <span class="n">f_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span>
                <span class="n">N_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span>
                <span class="n">u_kln</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span>
                <span class="c"># Weave inline C++ code.</span>
                <span class="n">code</span> <span class="o">=</span> <span class="s">&quot;&quot;&quot;</span>
<span class="s">        double log_terms[</span><span class="si">%(K)d</span><span class="s">]; // temporary storage for log terms</span>
<span class="s">        for (int k = 0; k &lt; K; k++) {</span>
<span class="s">          for (int n = 0; n &lt; N_K1(k); n++) {</span>
<span class="s">            double max_log_term = 0.0;</span>
<span class="s">            bool first_nonzero = true;</span>
<span class="s">            for (int j = 0; j &lt; K; j++) {</span>
<span class="s">              // skip empty states</span>
<span class="s">              if (N_K1(j) == 0) continue;</span>
<span class="s">              double log_term = log(N_K1(j)) + F_K1(j) - U_KLN3(k,j,n) + U_KN2(k,n);</span>
<span class="s">              log_terms[j] = log_term;</span>
<span class="s">              if (first_nonzero || (log_term &gt; max_log_term)) {</span>
<span class="s">                max_log_term = log_term;</span>
<span class="s">                first_nonzero = false;</span>
<span class="s">              }</span>
<span class="s">            }</span>

<span class="s">            double term_sum = 0.0;</span>
<span class="s">            for (int j = 0; j &lt; K; j++) {</span>
<span class="s">              // skip empty states</span>
<span class="s">              if (N_K1(j) == 0) continue;</span>
<span class="s">              term_sum += exp(log_terms[j] - max_log_term);</span>
<span class="s">            }</span>
<span class="s">            double log_term_sum = log(term_sum) + max_log_term;</span>
<span class="s">            LOG_W_KN2(k,n) = - log_term_sum;</span>
<span class="s">          }</span>
<span class="s">        }</span>
<span class="s">        &quot;&quot;&quot;</span> <span class="o">%</span> <span class="nb">vars</span><span class="p">()</span>
                <span class="c"># Execute inline C code with weave.</span>
                <span class="n">info</span> <span class="o">=</span> <span class="n">weave</span><span class="o">.</span><span class="n">inline</span><span class="p">(</span>
                    <span class="n">code</span><span class="p">,</span> <span class="p">[</span><span class="s">&#39;K&#39;</span><span class="p">,</span> <span class="s">&#39;N_k&#39;</span><span class="p">,</span> <span class="s">&#39;u_kn&#39;</span><span class="p">,</span> <span class="s">&#39;u_kln&#39;</span><span class="p">,</span> <span class="s">&#39;f_k&#39;</span><span class="p">,</span> <span class="s">&#39;log_w_kn&#39;</span><span class="p">],</span> <span class="n">headers</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;&lt;math.h&gt;&#39;</span><span class="p">,</span> <span class="s">&#39;&lt;stdlib.h&gt;&#39;</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="c"># Compute unnormalized log weights in pure Python.</span>
                <span class="n">log_w_kn</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_max</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">[</span><span class="n">k</span><span class="p">]):</span>
                        <span class="n">log_w_kn</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="n">_logsum</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_k</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span>
                                                   <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u_kln</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">,</span> <span class="n">n</span><span class="p">]</span> <span class="o">-</span> <span class="n">u_kn</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">]))</span>

        <span class="k">return</span> <span class="n">log_w_kn</span>

    <span class="c">#=========================================================================</span>
    <span class="k">def</span> <span class="nf">_amIdoneIterating</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f_k_new</span><span class="p">,</span> <span class="n">relative_tolerance</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">maximum_iterations</span><span class="p">,</span> <span class="n">print_warning</span><span class="p">,</span> <span class="n">verbose</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convenience function to test whether we are done iterating, same for all iteration types</span>

<span class="sd">        REQUIRED ARGUMENTS</span>
<span class="sd">          f_k_new (array): new free energies</span>
<span class="sd">          f_k (array) : older free energies</span>
<span class="sd">          relative_tolerance (float): the relative tolerance for terminating</span>
<span class="sd">          verbose (bool): verbose response</span>
<span class="sd">          iterations (int): current number of iterations</span>
<span class="sd">          print_warning (bool): sometimes, we want to surpress the warning.</span>

<span class="sd">        RETURN VALUES</span>
<span class="sd">           yesIam (bool): indicates that the iteration has converged.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">yesIam</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="c"># Compute change from old to new estimate.</span>
        <span class="n">Delta_f_k</span> <span class="o">=</span> <span class="n">f_k_new</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">]</span>

        <span class="c"># Check convergence criteria.</span>
        <span class="c"># Terminate when max((f - fold) / f) &lt; relative_tolerance for all</span>
        <span class="c"># nonzero f.</span>
        <span class="n">max_delta</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">max</span><span class="p">(</span>
            <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Delta_f_k</span><span class="p">)</span> <span class="o">/</span> <span class="n">numpy</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">f_k_new</span><span class="p">)))</span>

        <span class="c"># Update stored free energies.</span>
        <span class="n">f_k</span> <span class="o">=</span> <span class="n">f_k_new</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">f_k</span>

        <span class="c"># write out current estimate</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;current f_k for states with samples =&quot;</span>
            <span class="k">print</span> <span class="n">f_k</span>
            <span class="k">print</span> <span class="s">&quot;relative max_delta = </span><span class="si">%e</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">max_delta</span>

        <span class="c"># Check convergence criteria.</span>
        <span class="c"># Terminate when max((f - fold) / f) &lt; relative_tolerance for all</span>
        <span class="c"># nonzero f.</span>
        <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">max_delta</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">max_delta</span> <span class="o">&lt;</span> <span class="n">relative_tolerance</span><span class="p">):</span>
            <span class="n">yesIam</span> <span class="o">=</span> <span class="bp">True</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">yesIam</span><span class="p">):</span>
            <span class="c"># Report convergence, or warn user if convergence was not achieved.</span>
            <span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">f_k</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">):</span>
                <span class="c"># all f_k appear to be zero</span>
                <span class="k">print</span> <span class="s">&#39;WARNING: All f_k appear to be zero.&#39;</span>
            <span class="k">elif</span> <span class="p">(</span><span class="n">max_delta</span> <span class="o">&lt;</span> <span class="n">relative_tolerance</span><span class="p">):</span>
                <span class="c"># Convergence achieved.</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="k">print</span> <span class="s">&#39;Converged to tolerance of </span><span class="si">%e</span><span class="s"> in </span><span class="si">%d</span><span class="s"> iterations.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">max_delta</span><span class="p">,</span> <span class="n">iteration</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">elif</span> <span class="p">(</span><span class="n">print_warning</span><span class="p">):</span>
                <span class="c"># Warn that convergence was not achieved.</span>
                <span class="c"># many times, self-consistent iteration is used in conjunction with another program.  In that case,</span>
                <span class="c"># we don&#39;t really need to warn about anything, since we are not</span>
                <span class="c"># running it to convergence.</span>
                <span class="k">print</span> <span class="s">&#39;WARNING: Did not converge to within specified tolerance.&#39;</span>
                <span class="k">print</span> <span class="s">&#39;max_delta = </span><span class="si">%e</span><span class="s">, TOLERANCE = </span><span class="si">%e</span><span class="s">, MAX_ITS = </span><span class="si">%d</span><span class="s">, iterations completed = </span><span class="si">%d</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">max_delta</span><span class="p">,</span> <span class="n">relative_tolerance</span><span class="p">,</span> <span class="n">maximum_iterations</span><span class="p">,</span> <span class="n">iteration</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">yesIam</span>

    <span class="c">#=========================================================================</span>
    <span class="k">def</span> <span class="nf">_selfConsistentIteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">relative_tolerance</span><span class="o">=</span><span class="mf">1.0e-6</span><span class="p">,</span> <span class="n">maximum_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">print_warning</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determine free energies by self-consistent iteration.</span>

<span class="sd">        OPTIONAL ARGUMENTS</span>

<span class="sd">          relative_tolerance (float between 0 and 1) - relative tolerance for convergence (default 1.0e-5)</span>
<span class="sd">          maximum_iterations (int) - maximum number of self-consistent iterations (default 1000)</span>
<span class="sd">          verbose (boolean) - verbosity level for debug output</span>

<span class="sd">        NOTES</span>

<span class="sd">          Self-consistent iteration of the MBAR equations is used, as described in Appendix C.1 of [1].</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># Iteratively update dimensionless free energies until convergence to</span>
        <span class="c"># specified tolerance, or maximum allowed number of iterations has been</span>
        <span class="c"># exceeded.</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;MBAR: Computing dimensionless free energies by iteration.  This may take from seconds to minutes, depending on the quantity of data...&quot;</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">maximum_iterations</span><span class="p">):</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&#39;Self-consistent iteration </span><span class="si">%d</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">iteration</span>

            <span class="c"># compute the free energies by self consistent iteration (which</span>
            <span class="c"># also involves calculating the weights)</span>
            <span class="p">(</span><span class="n">W_nk</span><span class="p">,</span> <span class="n">f_k_new</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeWeights</span><span class="p">(</span>
                <span class="n">logform</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_f_k</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_amIdoneIterating</span><span class="p">(</span><span class="n">f_k_new</span><span class="p">,</span> <span class="n">relative_tolerance</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">maximum_iterations</span><span class="p">,</span> <span class="n">print_warning</span><span class="p">,</span> <span class="n">verbose</span><span class="p">)):</span>
                <span class="k">break</span>

        <span class="k">return</span>

    <span class="c">#=========================================================================</span>
    <span class="k">def</span> <span class="nf">_NewtonRaphson</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">first_gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">relative_tolerance</span><span class="o">=</span><span class="mf">1.0e-6</span><span class="p">,</span> <span class="n">maximum_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">print_warning</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determine dimensionless free energies by Newton-Raphson iteration.</span>

<span class="sd">        OPTIONAL ARGUMENTS</span>
<span class="sd">          first_gamma (float between 0 and 1) - step size multiplier to use for first step (default 0.1)</span>
<span class="sd">          gamma (float between 0 and 1) - step size multiplier for subsequent steps (default 1.0)</span>
<span class="sd">          relative_tolerance (float between 0 and 1) - relative tolerance for convergence (default 1.0e-6)</span>
<span class="sd">          maximum_iterations (int) - maximum number of Newton-Raphson iterations (default 1000)</span>
<span class="sd">          verbose (boolean) - verbosity level for debug output</span>

<span class="sd">        CAUTIONS</span>
<span class="sd">          This algorithm can sometimes cause the estimate to blow up -- we should add a check to make sure this doesn&#39;t happen, and switch</span>
<span class="sd">          to self-consistent iteration if it does.</span>

<span class="sd">        NOTES</span>
<span class="sd">          This method determines the dimensionless free energies by minimizing a convex function whose solution is the desired estimator.</span>
<span class="sd">          The original idea came from the construction of a likelihood function that independently reproduced the work of Geyer (see [1]</span>
<span class="sd">          and Section 6 of [2]).</span>
<span class="sd">          This can alternatively be formulated as a root-finding algorithm for the Z-estimator.</span>
<span class="sd">          More details of this procedure will follow in a subsequent paper.</span>
<span class="sd">          Only those states with nonzero counts are include in the estimation procedure.</span>

<span class="sd">        REFERENCES</span>
<span class="sd">          See Appendix C.2 of [1].</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c"># commenting out Newton-Raphson for now, adaptive replaces</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    if verbose: print &quot;Determining dimensionless free energies by Newton-Raphson iteration.&quot;</span>

<span class="sd">    K = self.K_nonzero</span>
<span class="sd">    N_k = self.N_nonzero</span>

<span class="sd">    # Perform Newton-Raphson iterations</span>
<span class="sd">    for iteration in range(0, maximum_iterations):</span>
<span class="sd">      if verbose: print &quot;Newton-Raphson iteration %d&quot; % iteration</span>

<span class="sd">      # Store for new estimate of dimensionless relative free energies.</span>
<span class="sd">      f_k_new = self.f_k[self.nonzero_N_k_indices].copy()</span>
<span class="sd">      </span>
<span class="sd">      # compute the weights</span>
<span class="sd">      W_nk = self._computeWeights()  </span>

<span class="sd">      # Compute gradient and Hessian of last (K-1) states.</span>
<span class="sd">      #</span>
<span class="sd">      # gradient (defined by Eq. C6 of [1])</span>
<span class="sd">      # g_i(theta) = N_i - \sum_n N_i W_ni</span>
<span class="sd">      #</span>
<span class="sd">      # Hessian (defined by Eq. C9 of [1])</span>
<span class="sd">      # H_ii(theta) = - \sum_n N_i W_ni (1 - N_i W_ni)</span>
<span class="sd">      # H_ij(theta) = \sum_n N_i W_ni N_j W_nj</span>
<span class="sd">      #</span>
<span class="sd">      # NOTE: Calculation of the gradient and Hessian could be further optimized.</span>

<span class="sd">      g = numpy.matrix(numpy.zeros([K-1,1], dtype=numpy.float64)) # gradient</span>
<span class="sd">      H = numpy.matrix(numpy.zeros([K-1,K-1], dtype=numpy.float64)) # Hessian</span>
<span class="sd">      for i in range(1,K):</span>
<span class="sd">        g[i-1] = N_k[i] - N_k[i] * W_nk[:,i].sum()</span>
<span class="sd">        H[i-1,i-1] = - (N_k[i] * W_nk[:,i] * (1.0 - N_k[i] * W_nk[:,i])).sum() </span>
<span class="sd">        for j in range(1,i):</span>
<span class="sd">          H[i-1,j-1] = (N_k[i] * W_nk[:,i] * N_k[j] * W_nk[:,j]).sum()</span>
<span class="sd">          H[j-1,i-1] = H[i-1,j-1]</span>

<span class="sd">      # Update the free energy estimate (Eq. C11 of [1]).</span>
<span class="sd">      Hinvg = numpy.linalg.lstsq(H,g)[0]      # solve the system of equations (may have less than full rank)</span>
<span class="sd">      #Hinvg = numpy.linalg.solve(H,g)  # if we can count on full rank, we can use this, which might be faster</span>
<span class="sd">      for k in range(0,K-1):   # offset by 1 because of the extra degree of freedom</span>
<span class="sd">        if iteration == 0:</span>
<span class="sd">          f_k_new[k+1] -= first_gamma * Hinvg[k]</span>
<span class="sd">        else:</span>
<span class="sd">          f_k_new[k+1] -= gamma * Hinvg[k]          </span>
<span class="sd">          </span>
<span class="sd">      if (self._amIdoneIterating(f_k_new,relative_tolerance,iteration,maximum_iterations,print_warning,verbose)): </span>
<span class="sd">        break;</span>

<span class="sd">    return</span>
<span class="sd">  &quot;&quot;&quot;</span>
    <span class="c"># commenting out likelihood minimization for now</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  #=============================================================================================</span>
<span class="sd">  def _minimizeLikelihood(self, relative_tolerance=1.0e-6, maximum_iterations=10000, verbose=True, print_warning = True):</span>
<span class="sd">      Determine dimensionless free energies by combined self-consistent and NR iteration, choosing the &#39;best&#39; each step.</span>
<span class="sd">  </span>
<span class="sd">    OPTIONAL ARGUMENTS</span>
<span class="sd">      relative_tolerance (float between 0 and 1) - relative tolerance for convergence (default 1.0e-6)</span>
<span class="sd">      maximum_iterations (int) - maximum number of minimizer iterations (default 1000)</span>
<span class="sd">      verbose (boolean) - verbosity level for debug output</span>
<span class="sd">  </span>
<span class="sd">    NOTES</span>
<span class="sd">      This method determines the dimensionless free energies by minimizing a convex function whose solution is the desired estimator.      </span>
<span class="sd">      The original idea came from the construction of a likelihood function that independently reproduced the work of Geyer (see [1]</span>
<span class="sd">      and Section 6 of [2]).</span>
<span class="sd">      This can alternatively be formulated as a root-finding algorithm for the Z-estimator.</span>
<span class="sd">  </span>
<span class="sd">    REFERENCES</span>
<span class="sd">      See Appendix C.2 of [1]. </span>
<span class="sd">  </span>
<span class="sd">      if verbose: print &quot;Determining dimensionless free energies by LBFG minimization&quot;</span>
<span class="sd">  </span>
<span class="sd">    # Number of states with samples.</span>
<span class="sd">    K = self.nonzero_N_k_indices.size</span>
<span class="sd">    if verbose:</span>
<span class="sd">      print &quot;There are %d states with samples.&quot; % K</span>
<span class="sd">  </span>
<span class="sd">    # Free energies</span>
<span class="sd">    f_k = self.f_k[self.nonzero_N_k_indices].copy()</span>
<span class="sd">      </span>
<span class="sd">    # Samples</span>
<span class="sd">    N_k = self.N_k[self.nonzero_N_k_indices].copy()</span>
<span class="sd">  </span>
<span class="sd">    from scipy import optimize</span>
<span class="sd">    </span>
<span class="sd">    results = optimize.fmin_cg(self._objectiveF,f_k,fprime=self._gradientF,gtol=relative_tolerance, full_output=verbose,disp=verbose,maxiter=maximum_iterations) </span>
<span class="sd">    # doesn&#39;t matter what starting point is -- it&#39;s determined by what is stored in self, not by &#39;dum&#39;</span>
<span class="sd">    #results = optimize.fmin(self._objectiveF,f_k,xtol=relative_tolerance, full_output=verbose,disp=verbose,maxiter=maximum_iterations) </span>
<span class="sd">    self.f_k = results[0]</span>
<span class="sd">    if verbose:</span>
<span class="sd">      print &quot;Obtained free energies by likelihood minimization&quot;        </span>
<span class="sd">  </span>
<span class="sd">    return  </span>
<span class="sd">  &quot;&quot;&quot;</span>
    <span class="c">#=========================================================================</span>

    <span class="k">def</span> <span class="nf">_adaptive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">relative_tolerance</span><span class="o">=</span><span class="mf">1.0e-8</span><span class="p">,</span> <span class="n">maximum_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">print_warning</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determine dimensionless free energies by a combination of Newton-Raphson iteration and self-consistent iteration.</span>
<span class="sd">        Picks whichever method gives the lowest gradient.</span>
<span class="sd">        Is slower than NR (approximated, not calculated) since it calculates the log norms twice each iteration.</span>

<span class="sd">        OPTIONAL ARGUMENTS</span>
<span class="sd">          gamma (float between 0 and 1) - incrementor for NR iterations.</span>
<span class="sd">          relative_tolerance (float between 0 and 1) - relative tolerance for convergence (default 1.0e-6)</span>
<span class="sd">          maximum_iterations (int) - maximum number of Newton-Raphson iterations (default 1000)</span>
<span class="sd">          verbose (boolean) - verbosity level for debug output</span>

<span class="sd">        NOTES</span>
<span class="sd">          This method determines the dimensionless free energies by minimizing a convex function whose solution is the desired estimator.</span>
<span class="sd">          The original idea came from the construction of a likelihood function that independently reproduced the work of Geyer (see [1]</span>
<span class="sd">          and Section 6 of [2]).</span>
<span class="sd">          This can alternatively be formulated as a root-finding algorithm for the Z-estimator.</span>
<span class="sd">          More details of this procedure will follow in a subsequent paper.</span>
<span class="sd">          Only those states with nonzero counts are include in the estimation procedure.</span>

<span class="sd">        REFERENCES</span>
<span class="sd">          See Appendix C.2 of [1].</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;Determining dimensionless free energies by Newton-Raphson iteration.&quot;</span>

        <span class="c"># nonzero versions of variables</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K_nonzero</span>
        <span class="n">N_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_nonzero</span>

        <span class="c"># keep track of Newton-Raphson and self-consistent iterations</span>
        <span class="n">nr_iter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">sci_iter</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">f_k_sci</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">f_k_new</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="c"># Perform Newton-Raphson iterations (with sci computed on the way)</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">maximum_iterations</span><span class="p">):</span>

            <span class="c"># Store for new estimate of dimensionless relative free energies.</span>
            <span class="n">f_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

            <span class="c"># compute weights for gradients: the denominators and free energies are from the previous</span>
            <span class="c"># iteration in most cases.</span>
            <span class="p">(</span><span class="n">W_nk</span><span class="p">,</span> <span class="n">f_k_sci</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeWeights</span><span class="p">(</span>
                <span class="n">recalc_denom</span><span class="o">=</span><span class="p">(</span><span class="n">iteration</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="n">return_f_k</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

            <span class="c"># Compute gradient and Hessian of last (K-1) states.</span>
            <span class="c">#</span>
            <span class="c"># gradient (defined by Eq. C6 of [1])</span>
            <span class="c"># g_i(theta) = N_i - \sum_n N_i W_ni</span>
            <span class="c">#</span>
            <span class="c"># Hessian (defined by Eq. C9 of [1])</span>
            <span class="c"># H_ii(theta) = - \sum_n N_i W_ni (1 - N_i W_ni)</span>
            <span class="c"># H_ij(theta) = \sum_n N_i W_ni N_j W_nj</span>
            <span class="c">#</span>

            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">      g = numpy.matrix(numpy.zeros([K-1,1], dtype=numpy.float64)) # gradient</span>
<span class="sd">      H = numpy.matrix(numpy.zeros([K-1,K-1], dtype=numpy.float64)) # Hessian</span>
<span class="sd">      for i in range(1,K):</span>
<span class="sd">        g[i-1] = N_k[i] - N_k[i] * W_nk[:,i].sum()</span>
<span class="sd">        H[i-1,i-1] = - (N_k[i] * W_nk[:,i] * (1.0 - N_k[i] * W_nk[:,i])).sum() </span>
<span class="sd">        for j in range(1,i):</span>
<span class="sd">          H[i-1,j-1] = (N_k[i] * W_nk[:,i] * N_k[j] * W_nk[:,j]).sum()</span>
<span class="sd">          H[j-1,i-1] = H[i-1,j-1]</span>

<span class="sd">      # Update the free energy estimate (Eq. C11 of [1]).</span>
<span class="sd">      Hinvg = numpy.linalg.lstsq(H,g)[0]      # </span>
<span class="sd">      # Hinvg = numpy.linalg.solve(H,g)       # This might be faster if we can guarantee full rank.</span>
<span class="sd">      for k in range(0,K-1):</span>
<span class="sd">        f_k_new[k+1] = f_k[k+1] - gamma*Hinvg[k]</span>

<span class="sd">      &quot;&quot;&quot;</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">N_k</span> <span class="o">-</span> <span class="n">N_k</span> <span class="o">*</span> <span class="n">W_nk</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">NW</span> <span class="o">=</span> <span class="n">N_k</span> <span class="o">*</span> <span class="n">W_nk</span>
            <span class="n">H</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">NW</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">NW</span><span class="p">)</span>
            <span class="n">H</span> <span class="o">+=</span> <span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">T</span> <span class="o">-</span> <span class="n">N_k</span><span class="p">)</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
            <span class="c"># Update the free energy estimate (Eq. C11 of [1]).</span>
            <span class="c"># will always have lower rank the way it is set up</span>
            <span class="n">Hinvg</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">g</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">Hinvg</span> <span class="o">-=</span> <span class="n">Hinvg</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">f_k_new</span> <span class="o">=</span> <span class="n">f_k</span> <span class="o">-</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">Hinvg</span>

            <span class="c"># self-consistent iteration gradient norm and saved log sums.</span>
            <span class="n">g_sci</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradientF</span><span class="p">(</span><span class="n">f_k_sci</span><span class="p">)</span>
            <span class="n">gnorm_sci</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">g_sci</span><span class="p">,</span> <span class="n">g_sci</span><span class="p">)</span>
            <span class="c"># save this so we can switch it back in if g_sci is lower.</span>
            <span class="n">log_weight_denom</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_weight_denom</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

            <span class="c"># newton raphson gradient norm and saved log sums.</span>
            <span class="n">g_nr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradientF</span><span class="p">(</span><span class="n">f_k_new</span><span class="p">)</span>
            <span class="n">gnorm_nr</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">g_nr</span><span class="p">,</span> <span class="n">g_nr</span><span class="p">)</span>

            <span class="c"># we could save the gradient, too, but it&#39;s not too expensive to</span>
            <span class="c"># compute since we are doing the Hessian anyway.</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;self consistent iteration gradient norm is </span><span class="si">%10.5g</span><span class="s">, Newton-Raphson gradient norm is </span><span class="si">%10.5g</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">gnorm_sci</span><span class="p">,</span> <span class="n">gnorm_nr</span><span class="p">)</span>
            <span class="c"># decide which directon to go depending on size of gradient norm</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">gnorm_sci</span> <span class="o">&lt;</span> <span class="n">gnorm_nr</span> <span class="ow">or</span> <span class="n">sci_iter</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">):</span>
                <span class="n">sci_iter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_weight_denom</span> <span class="o">=</span> <span class="n">log_weight_denom</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">sci_iter</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                        <span class="k">print</span> <span class="s">&quot;Choosing self-consistent iteration on iteration </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">iteration</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">print</span> <span class="s">&quot;Choosing self-consistent iteration for lower gradient on iteration </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">iteration</span>

                <span class="n">f_k_new</span> <span class="o">=</span> <span class="n">f_k_sci</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">nr_iter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="k">print</span> <span class="s">&quot;Newton-Raphson used on iteration </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">iteration</span>

            <span class="c"># get rid of big matrices that are not used.</span>
            <span class="k">del</span><span class="p">(</span><span class="n">log_weight_denom</span><span class="p">,</span> <span class="n">NW</span><span class="p">,</span> <span class="n">W_nk</span><span class="p">)</span>

            <span class="c"># have to set the free energies back in self, since the gradient</span>
            <span class="c"># routine changes them.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">f_k</span>
            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_amIdoneIterating</span><span class="p">(</span><span class="n">f_k_new</span><span class="p">,</span> <span class="n">relative_tolerance</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">maximum_iterations</span><span class="p">,</span> <span class="n">print_warning</span><span class="p">,</span> <span class="n">verbose</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="k">print</span> <span class="s">&#39;Of </span><span class="si">%d</span><span class="s"> iterations, </span><span class="si">%d</span><span class="s"> were Newton-Raphson iterations and </span><span class="si">%d</span><span class="s"> were self-consistent iterations&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">iteration</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nr_iter</span><span class="p">,</span> <span class="n">sci_iter</span><span class="p">)</span>
                <span class="k">break</span><span class="p">;</span>

        <span class="k">return</span>

    <span class="c">#=========================================================================</span>
    <span class="k">def</span> <span class="nf">_objectiveF</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f_k</span><span class="p">):</span>

        <span class="c"># gradient to integrate is: g_i = N_i - N_i \sum_{n=1}^N W_{ni}</span>
        <span class="c">#                              = N_i - N_i \sum_{n=1}^N exp(f_i-u_i) / \sum_{k=1} N_k exp(f_k-u_k)</span>
        <span class="c">#                              = N_i - N_i \sum_{n=1}^N exp(f_i-u_i) / \sum_{k=1} N_k exp(f_k-u_k)</span>
        <span class="c"># If we take F = \sum_{k=1}_{K} N_k f_k - \sum_{n=1}^N \ln [\sum_{k=1}_{K} N_k exp(f_k-u_k)]</span>
        <span class="c"># then:</span>
        <span class="c">#   dF/df_i = N_i - \sum_{n=1}^N \frac{1}{\sum_{k=1} N_k exp(f_k-u_k)} d/df_i [\sum_{k=1} N_k exp(f_k-u_k)]</span>
        <span class="c">#           = N_i - \sum_{n=1}^N \frac{1}{\sum_{k=1} N_k exp(f_k-u_k)} N_i exp(f_i-u_i)</span>
        <span class="c">#           = N_i - N_i\sum_{n=1}^N \frac{exp(f_i-u_i)}{\sum_{k=1} N_k exp(f_k-u_k)}</span>
        <span class="c">#           = N_i - N_i\sum_{n=1}^N W_{ni}</span>

        <span class="c"># actually using the negative, in order to maximize instead of minimize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">f_k</span>
        <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_nonzero</span><span class="p">,</span> <span class="n">f_k</span><span class="p">)</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_computeUnnormalizedLogWeights</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">K_nonzero</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_max</span><span class="p">]))))</span>

    <span class="c">#=========================================================================</span>
    <span class="k">def</span> <span class="nf">_gradientF</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f_k</span><span class="p">):</span>

        <span class="c"># take into account entries with zero samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_k</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">nonzero_N_k_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">f_k</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K_nonzero</span>
        <span class="n">N_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_nonzero</span>

        <span class="n">W_nk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_computeWeights</span><span class="p">(</span><span class="n">recalc_denom</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">g</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">K</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>  <span class="c"># gradient</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
            <span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">N_k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">N_k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">W_nk</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">g</span></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<a href="../../index.html"><img src="../../_static/pymbar.png" alt="Logo"/></a>

<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../../np-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">pymbar 2.0.0 documentation</a> |</li>
          <li><a href="../index.html" >Module code</a> |</li>
<a href="../../getting_started.html">Getting Started</a> |
<a href="https://github.com/choderalab/pymbar/issues">Bugs</a> |
<a href="../../examples/index.html">Examples</a> |
<a href="../../mdconvert.html"><span class="pre">mdconvert</span></a>
 

      </ul>
    </div>

    <div class="footer">
        &copy; Copyright 2013, Robert McGibbon and contributors.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-42143125-1', 'rmcgibbo.github.io');
  ga('send', 'pageview');
</script>

  </body>
</html>